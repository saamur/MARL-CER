{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%cd ../.."
   ],
   "id": "c0168c33b956ef0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from jax_tqdm import scan_tqdm\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly\n",
    "import seaborn as sns\n",
    "\n",
    "from plotly_resampler import register_plotly_resampler, FigureWidgetResampler\n",
    "# register_plotly_resampler(mode=\"auto\", default_n_shown_samples=4500)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from algorithms.utils import restore_state, restore_state_multi_agent\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "# jax.config.update(\"jax_enable_x64\", True)\n"
   ],
   "id": "a36c0d38023fb897"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ernestogym.envs_jax.multi_agent.env import RECEnv\n",
    "# from ernestogym.envs_jax.single_agent.env_trading_soc import MicroGridEnvSocAction"
   ],
   "id": "21c1c189c861a040"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def my_env_creator(params, battery_type, env_type='normal'):\n",
    "    if env_type == 'normal':\n",
    "        env = RECEnv(params, battery_type)\n",
    "    return env"
   ],
   "id": "1d41fa94e86f14de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def print_heatmap(X, Y, Z, num_bins=10, x_label='', y_label='', title='', n_decimals_axes=0):\n",
    "    z_grid, y_edges, x_edges = np.histogram2d(Y, X, bins=(num_bins, num_bins), weights=Z)\n",
    "    counts, _, _ = np.histogram2d(Y, X, bins=(num_bins, num_bins))\n",
    "\n",
    "    z_grid = np.divide(z_grid, counts, out=np.full_like(z_grid, fill_value=np.nan), where=counts > 0)\n",
    "\n",
    "    x_centers = (x_edges[1:]+x_edges[:-1])/2\n",
    "    y_centers = (y_edges[1:]+y_edges[:-1])/2\n",
    "\n",
    "    x_ticks = [f'{v:.{n_decimals_axes}f}' for v in x_centers]\n",
    "    y_ticks = [f'{v:.{n_decimals_axes}f}' for v in y_centers]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(z_grid, xticklabels=x_ticks, yticklabels=y_ticks, cmap='coolwarm', center=0).invert_yaxis()\n",
    "\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_hist_soc(soc, actions):\n",
    "    hist, bins = np.histogram(soc, weights=actions, bins=16)\n",
    "    counts, _ = np.histogram(soc, bins=16)\n",
    "\n",
    "    hist = np.divide(hist, counts, where=counts > 0)\n",
    "\n",
    "    bins_ctrs = (bins[:-1] + bins[1:])/2\n",
    "\n",
    "    plt.bar(bins_ctrs, hist, width=0.045)\n",
    "\n",
    "    plt.xlabel('SoC')\n",
    "    plt.ylabel('Mean action')"
   ],
   "id": "388a485b889e00d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from ernestogym.envs_jax.multi_agent.utils import parameter_generator",
   "id": "319e2b329f8fe3ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# pack_options = \"ernestogym/ernesto_jax/data/battery_new/pack.yaml\"\n",
    "# pack_options = \"ernestogym/ernesto_jax/data/battery_new/pack_cheap.yaml\"\n",
    "# pack_options = \"ernestogym/ernesto_jax/data/battery_new/pack_init_full.yaml\"\n",
    "# pack_options = \"ernestogym/ernesto_jax/data/battery_new/pack_init_full_cheap.yaml\"\n",
    "pack_options = \"ernestogym/ernesto_jax/data/battery_new/pack_init_half_full_cheap.yaml\"\n",
    "\n",
    "ecm = \"ernestogym/ernesto_jax/data/battery_new/models/electrical/thevenin_pack.yaml\"\n",
    "# ecm = \"ernestogym/ernesto_jax/data/battery_new/models/electrical/thevenin_fading_pack.yaml\"\n",
    "r2c = \"ernestogym/ernesto_jax/data/battery_new/models/thermal/r2c_thermal_pack.yaml\"\n",
    "# bolun = \"ernestogym/ernesto_jax/data/battery_new/models/aging/bolun_pack.yaml\"\n",
    "bolun = \"ernestogym/ernesto_jax/data/battery_new/models/aging/bolun_pack.yaml\"\n",
    "\n",
    "\n",
    "# world = \"ernestogym/envs_jax/multi_agent/world_deg_test.yaml\"\n",
    "# world = \"ernestogym/envs_jax/multi_agent/world_deg_test_exp_avg.yaml\"\n",
    "# world = \"ernestogym/envs_jax/multi_agent/world_deg_test_split_demands.yaml\"\n",
    "# world = \"ernestogym/envs_jax/single_agent/world_fading.yaml\"\n",
    "# world = \"ernestogym/envs_jax/multi_agent/world_deg_test_split_generations_only_trad_exp_avg.yaml\"\n",
    "# world = \"ernestogym/envs_jax/multi_agent/world_deg_test_split_generations_exp_avg.yaml\"\n",
    "# world = \"ernestogym/envs_jax/multi_agent/world_deg_test_split_generations_exp_avg_passive.yaml\"\n",
    "# world = \"ernestogym/envs_jax/multi_agent/world_deg_test_split_generations_exp_avg_new_clip.yaml\"\n",
    "# world = \"ernestogym/envs_jax/multi_agent/world_deg_test_split_demands_exp_avg.yaml\"\n",
    "# world = \"ernestogym/envs_jax/multi_agent/world_deg_test_all_the_same_debug_like_single.yaml\"\n",
    "\n",
    "world = 'ernestogym/envs_jax/multi_agent/world_deg_test_split_generations_passive_no_gen.yaml'\n",
    "# world = 'ernestogym/envs_jax/multi_agent/world_deg_test_split_generations_passive_scaled_no_gen.yaml'\n",
    "\n",
    "\n",
    "# battery_type = 'fading'\n",
    "# battery_type = 'degrading'\n",
    "battery_type = 'degrading_dropflow'\n",
    "\n",
    "params = parameter_generator(\n",
    "    input_var='current',\n",
    "    battery_options=pack_options,\n",
    "    electrical_model=ecm,\n",
    "    thermal_model=r2c,\n",
    "    aging_model=bolun,\n",
    "    world_options=world,\n",
    "    # use_reward_normalization=True\n",
    "\n",
    ")\n",
    "\n",
    "# num_iter = 8760 * 28\n",
    "\n",
    "params"
   ],
   "id": "c59c2ff5654d7529"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_iter = 8760 * 5     #len(params['demands_battery_houses'][0]['demand_profiles'])\n",
    "print(f'num profiles: {len(params['demands_battery_houses'][0]['demand_profiles'])}')"
   ],
   "id": "cc667ca09db1ca5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing",
   "id": "3aa8c83cb8595f26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "logs = {}",
   "id": "80c1a6cc9f71c0ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## PPO",
   "id": "2be9e8b5ac454e51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@partial(jax.jit, static_argnums=(0, 1, 2, 3))\n",
    "def test_ppo(env:RECEnv, networks_batteries, network_rec, num_iter, rng):\n",
    "\n",
    "    rng, _rng = jax.random.split(rng)\n",
    "\n",
    "    obsv, env_state = env.reset(_rng, profile_index=0)\n",
    "\n",
    "    @scan_tqdm(num_iter, print_rate=num_iter // 100)\n",
    "    def _env_step(runner_state, unused):\n",
    "        obsv_batteries, env_state, rng, next_profile_index = runner_state\n",
    "\n",
    "        pi, _ = networks_batteries(obsv_batteries)\n",
    "        #deterministic action\n",
    "        actions_batteries = pi.mode()\n",
    "        actions_batteries = actions_batteries.squeeze(axis=-1)\n",
    "        # jax.debug.print('act bat {x}', x=actions_batteries)\n",
    "\n",
    "\n",
    "        actions_first = {env.battery_agents[i]: actions_batteries[i] for i in range(env.num_battery_agents)}\n",
    "        actions_first[env.rec_agent] = jnp.zeros(env.num_battery_agents)\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state, reward_first, done_first, info_first = env.step(\n",
    "            _rng, env_state, actions_first\n",
    "        )\n",
    "\n",
    "        rec_obsv = obsv[env.rec_agent]\n",
    "\n",
    "        pi, _ = network_rec(rec_obsv)\n",
    "        actions_rec = pi.mean()\n",
    "\n",
    "        # jax.debug.print('{x}', x=pi.concentration)\n",
    "        # jax.debug.print('act {x}', x=actions_rec)\n",
    "\n",
    "        # actions_rec = jnp.zeros(env.num_battery_agents)\n",
    "\n",
    "        actions_second = {agent: jnp.array(0.) for agent in env.battery_agents}\n",
    "        actions_second[env.rec_agent] = actions_rec\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state, reward_second, done_second, info_second = env.step(\n",
    "            _rng, env_state, actions_second\n",
    "        )\n",
    "\n",
    "        done = jnp.logical_or(done_first['__all__'], done_second['__all__'])\n",
    "\n",
    "        info = jax.tree.map(lambda  x, y: x + y, info_first, info_second)\n",
    "\n",
    "        info['actions_batteries'] = actions_batteries\n",
    "        info['actions_rec'] = actions_rec\n",
    "        info['dones'] = jax.tree.map(lambda x, y : jnp.logical_or(x, y), done_first, done_second)\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state,next_profile_index = jax.lax.cond(done,\n",
    "                                                          lambda : env.reset(_rng, profile_index=next_profile_index) + (next_profile_index+1,),\n",
    "                                                          lambda : (obsv, env_state, next_profile_index))\n",
    "\n",
    "        obs_batteries = jnp.vstack([obsv[a] for a in env.battery_agents])\n",
    "\n",
    "        runner_state = (obs_batteries, env_state, rng, next_profile_index)\n",
    "        return runner_state, info\n",
    "\n",
    "    obsv_batteries = jnp.vstack([obsv[a] for a in env.battery_agents])\n",
    "\n",
    "    runner_state = (obsv_batteries, env_state, rng, 1)\n",
    "\n",
    "    runner_state, info = jax.lax.scan(_env_step, runner_state, jnp.arange(num_iter))\n",
    "\n",
    "    return info"
   ],
   "id": "99e142e3a0f3e30d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "directory = '/media/samuele/Disco/PycharmProjectsUbuntu/MARL-CER/trained_agents/20250324_135528_bat_net_type_actor_critic_rec_net_type_actor_critic_lr_bat_0.0001_lr_REC_cosine_tot_timesteps_5256000_lr_sched_cosine_multiagent/checkpoints/20250324_143540_7'\n",
    "\n",
    "networks_batteries, network_rec, config, params_training, train_info_ppo, val_info_ppo = restore_state_multi_agent(directory)"
   ],
   "id": "3e90a11dddd2d85a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "networks_batteries.log_std",
   "id": "14eeaa738cbb2ee0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "config",
   "id": "71cd38483c2df82a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "params_training",
   "id": "bc12777b91fdcde8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env = my_env_creator(params, battery_type, config['ENV_TYPE'])",
   "id": "f96fc0e4422be543"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "info = test_ppo(env, networks_batteries, network_rec, num_iter, jax.random.PRNGKey(51))\n",
    "logs['ppo'] = info"
   ],
   "id": "1a8c55d012e0a41f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "508f8d1ed4fac51b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "info",
   "id": "b3e131af4b1aa5a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# jax.tree.map(lambda x : x.shape, info)",
   "id": "78954f8e606618a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "info['demands'].shape",
   "id": "c5581ec3978e2911"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_heatmap(info['demands'].flatten(), info['generations'].flatten(), info['actions_batteries'].flatten(), x_label='Demand', y_label='Generation', title='Actions, batteries')",
   "id": "7d94b7c27d34e6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "info['actions_rec'].max()",
   "id": "80087a57be086c25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_heatmap((info['generations']-info['demands']-info['energy_to_batteries']).T.flatten(), np.tile(info['balance_plus'] - info['balance_minus'], reps=info['r_glob'].shape[1]), (info['r_glob'] - info['r_glob'].mean(axis=1, keepdims=True)).T.flatten(), x_label='Network exchange', y_label='Balance', title='Centered global reward')",
   "id": "3cd1b12a5d0e6e66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# print_heatmap((info['generations']-info['demands']-info['energy_to_batteries']).T.flatten(), np.tile(info['balance_plus'] - info['balance_minus'], reps=info['r_glob'].shape[1]), info['r_glob'].T.flatten(), x_label='Network exchange', y_label='Balance', title='Global reward')",
   "id": "ba2f6c64a822e9b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_hist_soc(logs['ppo']['soc'].flatten(), logs['ppo']['actions_batteries'].flatten())",
   "id": "e7565cf954d5e84c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Recurrent PPO",
   "id": "be5de819f000b5b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@partial(jax.jit, static_argnums=(0, 1, 2, 3))\n",
    "def test_recurrent_ppo(env:RECEnv, networks_batteries, network_rec, num_iter, rng):\n",
    "\n",
    "    rng, _rng = jax.random.split(rng)\n",
    "\n",
    "    obsv, env_state = env.reset(_rng, profile_index=0)\n",
    "\n",
    "    networks_batteries.eval()\n",
    "    network_rec.eval()\n",
    "\n",
    "    act_state_batteries, cri_state_batteries = networks_batteries.get_initial_lstm_state()\n",
    "    act_state_rec, cri_state_rec = network_rec.get_initial_lstm_state()\n",
    "\n",
    "    @scan_tqdm(num_iter, print_rate=num_iter // 100)\n",
    "    def _env_step(runner_state, unused):\n",
    "        obsv_batteries, env_state, act_state_batteries, act_state_rec, rng, next_profile_index = runner_state\n",
    "\n",
    "        pi, _, act_state_batteries, _ = networks_batteries(obsv_batteries, act_state_batteries, cri_state_batteries)\n",
    "        #deterministic action\n",
    "        actions_batteries = pi.mode()\n",
    "        actions_batteries = actions_batteries.squeeze(axis=-1)\n",
    "        # jax.debug.print('act bat {x}', x=actions_batteries)\n",
    "\n",
    "\n",
    "        actions_first = {env.battery_agents[i]: actions_batteries[i] for i in range(env.num_battery_agents)}\n",
    "        actions_first[env.rec_agent] = jnp.zeros(env.num_battery_agents)\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state, reward_first, done_first, info_first = env.step(\n",
    "            _rng, env_state, actions_first\n",
    "        )\n",
    "\n",
    "        rec_obsv = obsv[env.rec_agent]\n",
    "\n",
    "        pi, _, act_state_rec, _ = network_rec(rec_obsv, act_state_rec, cri_state_rec)\n",
    "        actions_rec = pi.mean()\n",
    "        # jax.debug.print('{x}', x=pi.concentration)\n",
    "        # jax.debug.print('act {x}', x=actions_rec)\n",
    "        # actions_rec = jnp.zeros(env.num_battery_agents)\n",
    "\n",
    "        actions_second = {agent: jnp.array(0.) for agent in env.battery_agents}\n",
    "        actions_second[env.rec_agent] = actions_rec\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state, reward_second, done_second, info_second = env.step(\n",
    "            _rng, env_state, actions_second\n",
    "        )\n",
    "\n",
    "        done = jnp.logical_or(done_first['__all__'], done_second['__all__'])\n",
    "\n",
    "        info = jax.tree.map(lambda  x, y: x + y, info_first, info_second)\n",
    "\n",
    "        info['actions_batteries'] = actions_batteries\n",
    "        info['actions_rec'] = actions_rec\n",
    "        info['dones'] = jax.tree.map(lambda x, y : jnp.logical_or(x, y), done_first, done_second)\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state,next_profile_index = jax.lax.cond(done,\n",
    "                                                          lambda : env.reset(_rng, profile_index=next_profile_index) + (next_profile_index+1,),\n",
    "                                                          lambda : (obsv, env_state, next_profile_index))\n",
    "\n",
    "        obs_batteries = jnp.vstack([obsv[a] for a in env.battery_agents])\n",
    "\n",
    "        runner_state = (obs_batteries, env_state, act_state_batteries, act_state_rec, rng, next_profile_index)\n",
    "        return runner_state, info\n",
    "\n",
    "    obsv_batteries = jnp.vstack([obsv[a] for a in env.battery_agents])\n",
    "\n",
    "    runner_state = (obsv_batteries, env_state, act_state_batteries, act_state_rec, rng, 1)\n",
    "\n",
    "    runner_state, info = jax.lax.scan(_env_step, runner_state, jnp.arange(num_iter))\n",
    "\n",
    "    return info"
   ],
   "id": "ce22973bf8685bd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# pack_options = \"ernestogym/ernesto_jax/data/battery_new/pack.yaml\"\n",
    "# pack_options = \"ernestogym/ernesto_jax/data/battery_new/pack_init_full_cheap.yaml\"\n",
    "pack_options = \"ernestogym/ernesto_jax/data/battery_new/pack_init_half_full_cheap.yaml\"\n",
    "\n",
    "ecm = \"ernestogym/ernesto_jax/data/battery_new/models/electrical/thevenin_pack.yaml\"\n",
    "# ecm = \"ernestogym/ernesto_jax/data/battery_new/models/electrical/thevenin_fading_pack.yaml\"\n",
    "r2c = \"ernestogym/ernesto_jax/data/battery_new/models/thermal/r2c_thermal_pack.yaml\"\n",
    "# bolun = \"ernestogym/ernesto_jax/data/battery_new/models/aging/bolun_pack.yaml\"\n",
    "bolun = \"ernestogym/ernesto_jax/data/battery_new/models/aging/bolun_pack.yaml\"\n",
    "\n",
    "\n",
    "# world = \"ernestogym/envs_jax/multi_agent/world_deg_test.yaml\"\n",
    "# world = \"ernestogym/envs_jax/multi_agent/world_deg_test_split_demands.yaml\"\n",
    "# world = \"ernestogym/envs_jax/single_agent/world_fading.yaml\"\n",
    "# world = \"ernestogym/envs_jax/multi_agent/world_deg_test_split_generations.yaml\"\n",
    "# world = \"ernestogym/envs_jax/multi_agent/world_deg_test_split_generations_new_clip.yaml\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# world = \"ernestogym/envs_jax/multi_agent/world_deg_test_split_generations_for_recurrent.yaml\"\n",
    "\n",
    "# world = 'ernestogym/envs_jax/multi_agent/world_deg_test_split_generations_for_recurrent_passive.yaml'\n",
    "# world = 'ernestogym/envs_jax/multi_agent/world_deg_test_split_generations_for_recurrent_passive_scaled.yaml'\n",
    "\n",
    "world = \"ernestogym/envs_jax/multi_agent/world_deg_test_split_generations_for_recurrent_passive_no_gen.yaml\"\n",
    "# world = \"ernestogym/envs_jax/multi_agent/world_deg_test_split_generations_for_recurrent_passive_scaled_no_gen.yaml\"\n",
    "\n",
    "\n",
    "\n",
    "# battery_type = 'fading'\n",
    "# battery_type = 'degrading'\n",
    "battery_type = 'degrading_dropflow'\n",
    "\n",
    "params = parameter_generator(\n",
    "    input_var='current',\n",
    "    battery_options=pack_options,\n",
    "    electrical_model=ecm,\n",
    "    thermal_model=r2c,\n",
    "    aging_model=bolun,\n",
    "    world_options=world,\n",
    "    # use_reward_normalization=True\n",
    "\n",
    ")\n",
    "\n",
    "# num_iter = 8760 * 28\n",
    "\n",
    "params"
   ],
   "id": "e74e1e1905f26cb5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "directory = '/media/samuele/Disco/PycharmProjectsUbuntu/MARL-CER/trained_agents/20250324_041758_bat_net_type_recurrent_actor_critic_rec_net_type_recurrent_actor_critic_lr_bat_0.0001_lr_REC_cosine_tot_timesteps_5256000_lr_sched_cosine_multiagent/checkpoints/20250324_061621_10'\n",
    "\n",
    "networks_batteries, network_rec, config, params_training, train_info_recurrent_ppo, val_info_recurrent_ppo = restore_state_multi_agent(directory)"
   ],
   "id": "a7352947ceb006e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env = my_env_creator(params, battery_type, config['ENV_TYPE'])",
   "id": "a6aa6be2c3d5458d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "params_training",
   "id": "3afb8648b8732ecc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "config",
   "id": "5ffdef3b16a5f4a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "info = test_recurrent_ppo(env, networks_batteries, network_rec, num_iter, jax.random.PRNGKey(51))\n",
    "logs['recurrent_ppo'] = info"
   ],
   "id": "f0ac9ab0979402e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_heatmap(info['demands'].flatten(), info['generations'].flatten(), info['actions_batteries'].flatten(), x_label='Demand', y_label='Generation', title='Actions, batteries')",
   "id": "dc8e1df7987d6f0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_heatmap((info['generations']-info['demands']-info['energy_to_batteries']).T.flatten(), np.tile(info['balance_plus'] - info['balance_minus'], reps=info['r_glob'].shape[1]), (info['r_glob'] - info['r_glob'].mean(axis=1, keepdims=True)).T.flatten(), x_label='Network exchange', y_label='Balance', title='Centered global reward')",
   "id": "73756ebf3dd15e9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# print_heatmap((info['generations']-info['demands']-info['energy_to_batteries']).T.flatten(), np.tile(info['balance_plus'] - info['balance_minus'], reps=info['r_glob'].shape[1]), info['r_glob'].T.flatten(), x_label='Network exchange', y_label='Balance', title='Global reward')",
   "id": "e93ed0ee8b52bed5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_hist_soc(logs['recurrent_ppo']['soc'].flatten(), logs['recurrent_ppo']['actions_batteries'].flatten())",
   "id": "4cb41698e3d79e87"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Random",
   "id": "8050796602cba446"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@partial(jax.jit, static_argnums=(0, 1))\n",
    "def test_random(env:RECEnv, num_iter, rng):\n",
    "\n",
    "    rng, _rng = jax.random.split(rng)\n",
    "\n",
    "    obsv, env_state = env.reset(_rng, profile_index=0)\n",
    "\n",
    "    @scan_tqdm(num_iter, print_rate=num_iter // 100)\n",
    "    def _env_step(runner_state, unused):\n",
    "        env_state, rng, next_profile_index = runner_state\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        actions_batteries = jax.random.uniform(_rng, shape=(env.num_battery_agents,), minval=env.i_min_action, maxval=env.i_max_action)\n",
    "\n",
    "        actions_first = {env.battery_agents[i]: actions_batteries[i] for i in range(env.num_battery_agents)}\n",
    "        actions_first[env.rec_agent] = jnp.zeros(env.num_battery_agents)\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state, reward_first, done_first, info_first = env.step(\n",
    "            _rng, env_state, actions_first\n",
    "        )\n",
    "\n",
    "        actions_rec = jnp.ones(env.num_battery_agents)/env.num_battery_agents\n",
    "\n",
    "        actions_second = {agent: jnp.array(0.) for agent in env.battery_agents}\n",
    "        actions_second[env.rec_agent] = actions_rec\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state, reward_second, done_second, info_second = env.step(\n",
    "            _rng, env_state, actions_second\n",
    "        )\n",
    "\n",
    "        done = jnp.logical_or(done_first['__all__'], done_second['__all__'])\n",
    "\n",
    "        info = jax.tree.map(lambda  x, y: x + y, info_first, info_second)\n",
    "\n",
    "        info['actions_batteries'] = actions_batteries\n",
    "        info['actions_rec'] = actions_rec\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state,next_profile_index = jax.lax.cond(done,\n",
    "                                                          lambda : env.reset(_rng, profile_index=next_profile_index) + (next_profile_index+1,),\n",
    "                                                          lambda : (obsv, env_state, next_profile_index))\n",
    "\n",
    "        runner_state = (env_state, rng, next_profile_index)\n",
    "        return runner_state, info\n",
    "\n",
    "    runner_state = (env_state, rng, 1)\n",
    "\n",
    "    runner_state, info = jax.lax.scan(_env_step, runner_state, jnp.arange(num_iter))\n",
    "\n",
    "    return info"
   ],
   "id": "21bdb0377bba85c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# info = test_random(env, num_iter, jax.random.PRNGKey(51))\n",
    "# logs['random'] = info"
   ],
   "id": "90f6187145bfc3c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Only market",
   "id": "55e12f35a17cd20d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@partial(jax.jit, static_argnums=(0, 1))\n",
    "def test_only_market(env:RECEnv, num_iter, rng):\n",
    "\n",
    "    rng, _rng = jax.random.split(rng)\n",
    "\n",
    "    obsv, env_state = env.reset(_rng, profile_index=0)\n",
    "\n",
    "    @scan_tqdm(num_iter, print_rate=num_iter // 100)\n",
    "    def _env_step(runner_state, unused):\n",
    "        env_state, rng, next_profile_index = runner_state\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        actions_batteries = jnp.zeros((env.num_battery_agents,))# + jax.random.normal(_rng)*(jnp.e**(-1))# + 0.01 * jnp.sin((unused%8760)*(2*jnp.pi) * 1./8760)\n",
    "\n",
    "        # actions_batteries = jax.lax.select(unused < 8760, actions_batteries+0.01*365 * jnp.sin((unused%8760)*(2*jnp.pi) * 365./8760), actions_batteries)\n",
    "\n",
    "        actions_first = {env.battery_agents[i]: actions_batteries[i] for i in range(env.num_battery_agents)}\n",
    "        actions_first[env.rec_agent] = jnp.zeros(env.num_battery_agents)\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state, reward_first, done_first, info_first = env.step(\n",
    "            _rng, env_state, actions_first\n",
    "        )\n",
    "\n",
    "        actions_rec = jnp.ones(env.num_battery_agents)/env.num_battery_agents\n",
    "\n",
    "        actions_second = {agent: jnp.array(0.) for agent in env.battery_agents}\n",
    "        actions_second[env.rec_agent] = actions_rec\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state, reward_second, done_second, info_second = env.step(\n",
    "            _rng, env_state, actions_second\n",
    "        )\n",
    "\n",
    "        done = jnp.logical_or(done_first['__all__'], done_second['__all__'])\n",
    "\n",
    "        info = jax.tree.map(lambda  x, y: x + y, info_first, info_second)\n",
    "\n",
    "        info['actions_batteries'] = actions_batteries\n",
    "        info['actions_rec'] = actions_rec\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state,next_profile_index = jax.lax.cond(done,\n",
    "                                                          lambda : env.reset(_rng, profile_index=next_profile_index) + (next_profile_index+1,),\n",
    "                                                          lambda : (obsv, env_state, next_profile_index))\n",
    "\n",
    "        runner_state = (env_state, rng, next_profile_index)\n",
    "        return runner_state, info\n",
    "\n",
    "    runner_state = (env_state, rng, 1)\n",
    "\n",
    "    runner_state, info = jax.lax.scan(_env_step, runner_state, jnp.arange(num_iter))\n",
    "\n",
    "    return info"
   ],
   "id": "145648ba68c57ae9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "info = test_only_market(env, num_iter, jax.random.PRNGKey(51))\n",
    "logs['only_market'] = info"
   ],
   "id": "b944752914e1661e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "np.sum(info['pure_reward']['r_deg'][:, 0])",
   "id": "ba75f947b33fd774"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Battery first",
   "id": "e5a6ae197bd2d1ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@partial(jax.jit, static_argnums=(0, 1))\n",
    "def test_battery_first(env:RECEnv, num_iter, rng):\n",
    "\n",
    "    rng, _rng = jax.random.split(rng)\n",
    "\n",
    "    obsv, env_state = env.reset(_rng, profile_index=0)\n",
    "\n",
    "    @scan_tqdm(num_iter, print_rate=num_iter // 100)\n",
    "    def _env_step(runner_state, unused):\n",
    "        obsv_batteries, env_state, rng, next_profile_index = runner_state\n",
    "\n",
    "        demand = obsv_batteries[:, env._obs_battery_agents_idx['demand']]\n",
    "        generation = obsv_batteries[:, env._obs_battery_agents_idx['generation']]\n",
    "\n",
    "        actions_batteries = (generation - demand) / env_state.battery_states.electrical_state.v\n",
    "\n",
    "\n",
    "        actions_first = {env.battery_agents[i]: actions_batteries[i] for i in range(env.num_battery_agents)}\n",
    "        actions_first[env.rec_agent] = jnp.zeros(env.num_battery_agents)\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state, reward_first, done_first, info_first = env.step(\n",
    "            _rng, env_state, actions_first\n",
    "        )\n",
    "\n",
    "        actions_rec = jnp.ones(env.num_battery_agents)/env.num_battery_agents\n",
    "\n",
    "        actions_second = {agent: jnp.array(0.) for agent in env.battery_agents}\n",
    "        actions_second[env.rec_agent] = actions_rec\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state, reward_second, done_second, info_second = env.step(\n",
    "            _rng, env_state, actions_second\n",
    "        )\n",
    "\n",
    "        done = jnp.logical_or(done_first['__all__'], done_second['__all__'])\n",
    "\n",
    "        info = jax.tree.map(lambda  x, y: x + y, info_first, info_second)\n",
    "\n",
    "        info['actions_batteries'] = actions_batteries\n",
    "        info['actions_rec'] = actions_rec\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state,next_profile_index = jax.lax.cond(done,\n",
    "                                                          lambda : env.reset(_rng, profile_index=next_profile_index) + (next_profile_index+1,),\n",
    "                                                          lambda : (obsv, env_state, next_profile_index))\n",
    "\n",
    "        obs_batteries = jnp.vstack([obsv[a] for a in env.battery_agents])\n",
    "\n",
    "        runner_state = (obs_batteries, env_state, rng, next_profile_index)\n",
    "        return runner_state, info\n",
    "\n",
    "    obsv_batteries = jnp.vstack([obsv[a] for a in env.battery_agents])\n",
    "\n",
    "    runner_state = (obsv_batteries, env_state, rng, 1)\n",
    "\n",
    "    runner_state, info = jax.lax.scan(_env_step, runner_state, jnp.arange(num_iter))\n",
    "\n",
    "    return info"
   ],
   "id": "ba5883b5846051f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "info = test_battery_first(env, num_iter, jax.random.PRNGKey(51))\n",
    "logs['battery_first'] = info"
   ],
   "id": "b19797641d86bf01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(info['weig_reward']['r_trad'].sum(axis=0))\n",
    "print(info['weig_reward']['r_deg'].sum(axis=0))"
   ],
   "id": "63f80a738eb67203"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "78b12774bbb1a63e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "jax.tree.map(lambda x: x.shape, logs)",
   "id": "b0ca02a93c86d141"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# jax.tree.map(lambda x: x.shape, logs['ppo'])",
   "id": "e4d5552c13c337e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plotting",
   "id": "e14c45ed770e8863"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "logs = jax.tree.map(lambda x : np.asarray(x), logs)\n",
    "\n",
    "algs = ['ppo', 'recurrent_ppo']"
   ],
   "id": "3a127a9884134a8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# logs['ppo']['actions_rec'][28109]",
   "id": "1bfaea9a3646aa30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "np.sum(np.isnan(logs['ppo']['actions_rec']).any(axis=1))",
   "id": "300a6106b00e9327"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# logs['ppo']['actions_rec']",
   "id": "6b6b6462b9b848b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# jax.tree.map(lambda x: jnp.isnan(x).any(), logs['recurrent_ppo'])",
   "id": "9b308d540c491201"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a4f87e6fe31fab44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print('Tot self consumption')\n",
    "for alg in algs:\n",
    "    print(f'\\t{alg}: {np.sum(logs[alg]['self_consumption'])}')\n",
    "\n",
    "print('Tot reward')\n",
    "for alg in algs:\n",
    "    print(f'\\t{alg}: {np.sum(logs[alg]['r_tot'])}')\n",
    "\n",
    "print('Tot glob reward')\n",
    "for alg in algs:\n",
    "    print(f'\\t{alg}: {np.sum(logs[alg]['r_glob'])}')\n",
    "\n",
    "print('Tot trad reward')\n",
    "for alg in algs:\n",
    "    print(f'\\t{alg}: {np.sum(logs[alg]['weig_reward']['r_trad'])}')\n",
    "\n",
    "print('Tot deg reward')\n",
    "for alg in algs:\n",
    "    print(f'\\t{alg}: {np.sum(logs[alg]['weig_reward']['r_deg'])}')\n",
    "\n",
    "print('Tot clipping reward')\n",
    "for alg in algs:\n",
    "    print(f'\\t{alg}: {np.sum(logs[alg]['weig_reward']['r_clipping'])}')\n",
    "\n",
    "print('Tot rec reward')\n",
    "for alg in algs:\n",
    "    print(f'\\t{alg}: {np.sum(logs[alg]['rec_reward'])}')\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Mean rec actions')\n",
    "for alg in algs:\n",
    "    print(f'\\t{alg}: {np.mean(logs[alg]['actions_rec'], axis=0)}')\n",
    "print('Mean of variance rec actions')\n",
    "for alg in algs:\n",
    "    print(f'\\t{alg}: {np.mean(np.var(logs[alg]['actions_rec'], axis=1))}')\n",
    "print('Mean of difference max-min rec actions')\n",
    "for alg in algs:\n",
    "    print(f'\\t{alg}: {np.mean(np.max(logs[alg]['actions_rec'], axis=1) - np.min(logs[alg]['actions_rec'], axis=1))}')\n",
    "\n",
    "print('Pearson correlation coeff')\n",
    "for alg in algs:\n",
    "    v1 = logs[alg]['actions_rec']\n",
    "    v2 = (logs[alg]['generations']-logs[alg]['demands']-logs[alg]['energy_to_batteries']) * (logs[alg]['balance_plus'] - logs[alg]['balance_minus'])[:, None]\n",
    "    coeff = np.mean((v1 - v1.mean(axis=0, keepdims=True)) * (v2 - v2.mean(axis=0, keepdims=True)), axis=0)\n",
    "    norm_coeff = coeff/np.sqrt(np.var(v1, axis=0)*np.var(v2, axis=0))\n",
    "    print(f'\\t{alg}: {coeff}\\t\\t{norm_coeff}')\n"
   ],
   "id": "64ce0ca0b4311a9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "alg = 'ppo'\n",
    "\n",
    "# a = logs[alg]['actions_rec'].T.flatten()\n",
    "a = (logs[alg]['r_glob'] - logs[alg]['r_glob'].mean(axis=1, keepdims=True)).T.flatten()\n",
    "\n",
    "b = (logs[alg]['generations']-logs[alg]['demands']-logs[alg]['energy_to_batteries']).T.flatten()\n",
    "c = np.tile(logs[alg]['balance_plus'] - logs[alg]['balance_minus'], reps=logs[alg]['r_glob'].shape[1])\n",
    "\n",
    "print(np.corrcoef(b, c)[0, 1])\n",
    "\n",
    "X = np.column_stack((b, c, b * c))  # Independent variables\n",
    "X = sm.add_constant(X)  # Add intercept\n",
    "model = sm.OLS(a, X).fit()\n",
    "\n",
    "print(model.summary())"
   ],
   "id": "75d42c94bf4dcedc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "X = np.column_stack((b, c, b * c))\n",
    "vif = [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "print(vif)"
   ],
   "id": "510cdb1b5c0235a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "v1 = logs['recurrent_ppo']['actions_rec'][:, 0]\n",
    "v2 = (logs['recurrent_ppo']['generations'][:, 0]-logs['recurrent_ppo']['demands'][:, 0]-logs['recurrent_ppo']['energy_to_batteries'][:, 0]) * (logs['recurrent_ppo']['balance_plus'] - logs['recurrent_ppo']['balance_minus'])\n",
    "\n",
    "print(np.corrcoef(v1, v2))\n",
    "\n",
    "print(v1.shape)\n",
    "print(v2.shape)\n",
    "\n",
    "\n",
    "np.mean((v1-v1.mean()) * (v2-v2.mean())) / np.sqrt(np.var(v1)*np.var(v2))"
   ],
   "id": "8a071fcf07ae431d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "logs['ppo']['actions_rec'].shape",
   "id": "ad030024362594"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "logs['ppo']['self_consumption']",
   "id": "5d9fa1b6b6dacd75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ac = logs['ppo']['actions_batteries']\n",
    "\n",
    "ac.min(), ac.max(), ac.mean(), np.var(ac)"
   ],
   "id": "8964806f78130fbd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "logs['ppo']['actions_rec'].mean(axis=0)",
   "id": "66d912b0d7ff0034"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# train_info_ppo['actions']['battery_agent_0'].shape#, train_info_ppo['actions']['battery_agent_0'].max()",
   "id": "24645979ef533679"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# val_info_ppo['actions_batteries'].max(axis=(1, 2)), val_info_ppo['actions_batteries'].min(axis=(1, 2))",
   "id": "e227762768aa0299"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "algs = ['random', 'only_market', 'battery_first', 'ppo', 'recurrent_ppo']        #, 'recurrent_ppo']\n",
    "# colors = {alg: col for alg, col in zip(algs, plotly.colors.sample_colorscale('rainbow', len(algs)))}\n",
    "colors = plotly.colors.sample_colorscale('rainbow', env.num_battery_agents)\n",
    "line_styles = {'random': 'dot',\n",
    "               'only_market': 'dash',\n",
    "               'battery_first': 'dashdot',\n",
    "               'ppo': 'solid',\n",
    "               'recurrent_ppo': 'longdash'}\n",
    "\n",
    "def plot_data_plotly(demands, generations, sell_prices, buy_prices, log, algs, full_algs, time_step, reward_type='weig_reward', cumulative=True):\n",
    "\n",
    "    n_points = max(demands.shape[0], generations.shape[0], sell_prices.shape[0], buy_prices.shape[0])\n",
    "    # print(n_points)\n",
    "    # print(demands.shape)\n",
    "\n",
    "    time = pd.date_range('2015-01-01', periods=n_points, freq=str(int(time_step))+'s')\n",
    "    fig = FigureWidgetResampler(make_subplots(rows=13, cols=1, shared_xaxes=True, vertical_spacing = 0.02, subplot_titles=['Power demand and generation', 'Market prices', 'SoC', 'Trad plus deg plus glob reward', 'Trading reward', 'Degradation reward', 'Clipping reward', 'Global reward', 'Actions', 'REC actions', 'REC reward','REC balances', 'Network exchange']), default_n_shown_samples=5000)\n",
    "    # fig = make_subplots(rows=11, cols=1, shared_xaxes=True, vertical_spacing = 0.05, subplot_titles=['Power demand and generation', 'Market prices', 'SoC', 'Total reward', 'Trading reward', 'Degradation reward', 'Clipping reward', 'Global reward', 'Actions', 'REC reward', 'REC balances'])\n",
    "\n",
    "    # print(time.shape)\n",
    "    # print(demands[: 0].shape)\n",
    "\n",
    "    for i in range(demands.shape[1]):\n",
    "        fig.add_trace(go.Scatter(x=time, y=demands[:, i], mode='lines', legend='legend1', name=f'demand agent{i}', line=dict(color=colors[i], dash='solid')), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=generations[:, i], mode='lines', legend='legend1', name=f'generation agent{i}', line=dict(color=colors[i], dash='dot')), row=1, col=1)\n",
    "\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=time, y=sell_prices[:, 0]*1000000, mode='lines', legend='legend2', name='Selling prices'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=time, y=buy_prices[:, 0]*1000000, mode='lines', legend='legend2', name='Buying prices'), row=2, col=1)\n",
    "\n",
    "    rewards = {}\n",
    "    for alg in algs:\n",
    "        rewards[alg] = {}\n",
    "\n",
    "    if cumulative:\n",
    "        for alg in algs:\n",
    "            rewards[alg]['r_tot'] = np.cumsum(log[alg]['r_tot'], axis=0)\n",
    "            rewards[alg]['r_trad'] = np.cumsum(log[alg][reward_type]['r_trad'], axis=0)\n",
    "            rewards[alg]['r_deg'] = np.cumsum(log[alg][reward_type]['r_deg'], axis=0)\n",
    "            rewards[alg]['r_clipping'] = np.cumsum(log[alg][reward_type]['r_clipping'], axis=0)\n",
    "            rewards[alg]['r_glob'] = np.cumsum(log[alg]['r_glob'], axis=0)\n",
    "            rewards[alg]['r_rec'] = np.cumsum(log[alg]['rec_reward'])\n",
    "    else:\n",
    "        for alg in algs:\n",
    "            rewards[alg]['r_tot'] = log[alg]['r_tot']\n",
    "            rewards[alg]['r_trad'] = log[alg][reward_type]['r_trad']\n",
    "            rewards[alg]['r_deg'] = log[alg][reward_type]['r_deg']\n",
    "            rewards[alg]['r_clipping'] = log[alg][reward_type]['r_clipping']\n",
    "            rewards[alg]['r_glob'] = log[alg]['r_glob']\n",
    "            rewards[alg]['r_rec'] = log[alg]['rec_reward']\n",
    "\n",
    "    for alg in full_algs:\n",
    "        for i in range(demands.shape[1]):\n",
    "            fig.add_trace(go.Scatter(x=time, y=log[alg]['soc'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend3', name=f'{alg} agent {i}'), row=3, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_trad'][:, i]+rewards[alg]['r_deg'][:, i]+rewards[alg]['r_glob'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend4', name=f'{alg} agent {i}'), row=4, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_trad'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend5', name=f'{alg} agent {i}'), row=5, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_deg'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend6', name=f'{alg} agent {i}'), row=6, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_clipping'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend7', name=f'{alg} agent {i}'), row=7, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_glob'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend8', name=f'{alg} agent {i}'), row=8, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=log[alg]['actions_batteries'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend9', name=f'{alg} agent {i}'), row=9, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=log[alg]['generations'][:, i]-log[alg]['demands'][:, i]-log[alg]['energy_to_batteries'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend13', name=f'{alg} agent {i}'), row=13, col=1)\n",
    "\n",
    "    for alg in [alg for alg in algs if alg not in full_algs]:\n",
    "        fig.add_trace(go.Scatter(x=time, y=log[alg]['soc'].mean(axis=1), line=dict(color='grey', dash=line_styles[alg]), mode='lines', legend='legend3', name=alg), row=3, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_trad'].mean(axis=1) + rewards[alg]['r_deg'].mean(axis=1) + rewards[alg]['r_glob'].mean(axis=1), line=dict(color='grey', dash=line_styles[alg]), mode='lines', legend='legend4', name=alg), row=4, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_trad'].mean(axis=1), line=dict(color='grey', dash=line_styles[alg]), mode='lines', legend='legend5', name=alg), row=5, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_deg'].mean(axis=1), line=dict(color='grey', dash=line_styles[alg]), mode='lines', legend='legend6', name=alg), row=6, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_clipping'].mean(axis=1), line=dict(color='grey', dash=line_styles[alg]), mode='lines', legend='legend7', name=alg), row=7, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_glob'].mean(axis=1), line=dict(color='grey', dash=line_styles[alg]), mode='lines', legend='legend8', name=alg), row=8, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=log[alg]['actions_batteries'].mean(axis=1), line=dict(color='grey', dash=line_styles[alg]), mode='lines', legend='legend9', name=alg), row=9, col=1)\n",
    "\n",
    "    print(log[alg]['actions_rec'][0].shape, time.shape)\n",
    "\n",
    "    for alg in algs:\n",
    "        for i in range(demands.shape[1]):\n",
    "            fig.add_trace(go.Scatter(x=time, y=log[alg]['actions_rec'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend10', name=alg), row=10, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_rec'], line=dict(color='grey', dash=line_styles[alg]), mode='lines', legend='legend11', name=alg), row=11, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=log[alg]['balance_plus'], line=dict(color='green', dash=line_styles[alg]), mode='lines', legend='legend12', name=alg), row=12, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=log[alg]['balance_minus'], line=dict(color='red', dash=line_styles[alg]), mode='lines', legend='legend12', name=alg), row=12, col=1)\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='',\n",
    "        xaxis=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis2=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis3=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis4=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis5=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis6=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis7=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis8=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis9=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis10=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis11=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis12=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis13=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "\n",
    "        yaxis=dict(fixedrange=True, title='Wh', minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis2=dict(fixedrange=True, title='/MWh', minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis3=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis4=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis5=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis6=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis7=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis8=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis9=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis10=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis11=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis12=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis13=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "\n",
    "        height=3000,\n",
    "        width=1200,\n",
    "        legend_tracegroupgap=20\n",
    "    )\n",
    "\n",
    "    # fig.update_layout(\n",
    "    # legends=[\n",
    "    #     dict(x=1.05, y=0.95, tracegroup=\"group1\"),  # Legend for first subplot\n",
    "    #     dict(x=1.05, y=0.60, tracegroup=\"group2\"),  # Legend for second subplot\n",
    "    # ]\n",
    "    # )\n",
    "\n",
    "    fig.update_layout(\n",
    "        legend1=dict(\n",
    "            xref=\"container\",\n",
    "            yref=\"container\",\n",
    "            y=0.6),\n",
    "        legend2=dict(\n",
    "            xref=\"container\",\n",
    "            yref=\"container\",\n",
    "            y=0.1)\n",
    "    )\n",
    "\n",
    "    fig.write_html(directory + '/plots.html')\n",
    "    print(directory + '/plots.html')\n",
    "\n",
    "\n",
    "    display(fig)"
   ],
   "id": "bc4a40e1ba1081cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "logs['ppo']['actions_rec'].shape, logs['ppo']['r_tot'].shape",
   "id": "e550eb0b2580dfe3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env.init_state.battery_states.nominal_cost",
   "id": "fd0e7da80e188a99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# plot_external_data_matplotlib(logs['ppo']['demand'], logs['ppo']['generation'], logs['ppo']['sell_price'], logs['ppo']['buy_price'], start=1000, length_max=200)\n",
    "# algs_to_plot = ['only_market', 'battery_first', 'ppo', 'recurrent_ppo']\n",
    "algs_to_plot = ['battery_first', 'only_market', 'ppo', 'recurrent_ppo']#, 'battery_first']\n",
    "# algs_to_plot = ['ppo']      # ['only_market', 'ppo', 'recurrent_ppo']\n",
    "full_algs = ['ppo', 'recurrent_ppo'] #['battery_first', 'only_market', 'recurrent_ppo']#, 'battery_first'] #['ppo']      #['only_market', 'ppo', 'recurrent_ppo']\n",
    "\n",
    "dem_agent = algs_to_plot[0] # 'recurrent_ppo'\n",
    "\n",
    "plot_data_plotly(logs[dem_agent]['demands'], logs[dem_agent]['generations'], logs[dem_agent]['sell_prices'], logs[dem_agent]['buy_prices'], logs, algs_to_plot, full_algs, env.env_step, reward_type='weig_reward', cumulative=True)"
   ],
   "id": "10aeb41dae7487d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "algs = ['random', 'only_market', 'battery_first', 'ppo', 'recurrent_ppo']        #, 'recurrent_ppo']\n",
    "# colors = {alg: col for alg, col in zip(algs, plotly.colors.sample_colorscale('rainbow', len(algs)))}\n",
    "colors = plotly.colors.sample_colorscale('rainbow', env.num_battery_agents)\n",
    "line_styles = {'random': 'dot',\n",
    "               'only_market': 'dash',\n",
    "               'battery_first': 'dashdot',\n",
    "               'ppo': 'solid',\n",
    "               'recurrent_ppo': 'longdash'}\n",
    "\n",
    "def plot_data_plotly(demands, generations, sell_prices, buy_prices, log, algs, full_algs, time_step, reward_type='weig_reward', cumulative=True):\n",
    "\n",
    "    n_points = max(demands.shape[0], generations.shape[0], sell_prices.shape[0], buy_prices.shape[0])\n",
    "    # print(n_points)\n",
    "    # print(demands.shape)\n",
    "\n",
    "    time = pd.date_range('2015-01-01', periods=n_points, freq=str(int(time_step))+'s')\n",
    "    fig = FigureWidgetResampler(make_subplots(rows=13, cols=1, shared_xaxes=True, vertical_spacing = 0.02, subplot_titles=['Power demand and generation', 'Market prices', 'SoC', 'Trad plus deg plus glob reward', 'Trading reward', 'Degradation reward', 'Clipping reward', 'Global reward', 'Actions', 'REC actions', 'REC reward','REC balances', 'Network exchange']), default_n_shown_samples=5000)\n",
    "    # fig = make_subplots(rows=11, cols=1, shared_xaxes=True, vertical_spacing = 0.05, subplot_titles=['Power demand and generation', 'Market prices', 'SoC', 'Total reward', 'Trading reward', 'Degradation reward', 'Clipping reward', 'Global reward', 'Actions', 'REC reward', 'REC balances'])\n",
    "\n",
    "    # print(time.shape)\n",
    "    # print(demands[: 0].shape)\n",
    "\n",
    "    for i in range(demands.shape[1]):\n",
    "        fig.add_trace(go.Scatter(x=time, y=demands[:, i], mode='lines', legend='legend1', name=f'demand agent{i}', line=dict(color=colors[i], dash='solid')), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=generations[:, i], mode='lines', legend='legend1', name=f'generation agent{i}', line=dict(color=colors[i], dash='dot')), row=1, col=1)\n",
    "\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=time, y=sell_prices[:, 0]*1000000, mode='lines', legend='legend2', name='Selling prices'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=time, y=buy_prices[:, 0]*1000000, mode='lines', legend='legend2', name='Buying prices'), row=2, col=1)\n",
    "\n",
    "    rewards = {}\n",
    "    for alg in algs:\n",
    "        rewards[alg] = {}\n",
    "\n",
    "    if cumulative:\n",
    "        for alg in algs:\n",
    "            rewards[alg]['r_tot'] = np.cumsum(log[alg]['r_tot'], axis=0)\n",
    "            rewards[alg]['r_trad'] = np.cumsum(log[alg][reward_type]['r_trad'], axis=0)\n",
    "            rewards[alg]['r_deg'] = np.cumsum(log[alg][reward_type]['r_deg'], axis=0)\n",
    "            rewards[alg]['r_clipping'] = np.cumsum(log[alg][reward_type]['r_clipping'], axis=0)\n",
    "            rewards[alg]['r_glob'] = np.cumsum(log[alg]['r_glob'], axis=0)\n",
    "            rewards[alg]['r_rec'] = np.cumsum(log[alg]['rec_reward'])\n",
    "    else:\n",
    "        for alg in algs:\n",
    "            rewards[alg]['r_tot'] = log[alg]['r_tot']\n",
    "            rewards[alg]['r_trad'] = log[alg][reward_type]['r_trad']\n",
    "            rewards[alg]['r_deg'] = log[alg][reward_type]['r_deg']\n",
    "            rewards[alg]['r_clipping'] = log[alg][reward_type]['r_clipping']\n",
    "            rewards[alg]['r_glob'] = log[alg]['r_glob']\n",
    "            rewards[alg]['r_rec'] = log[alg]['rec_reward']\n",
    "\n",
    "    for alg in full_algs:\n",
    "        for i in range(demands.shape[1]):\n",
    "            fig.add_trace(go.Scatter(x=time, y=log[alg]['soc'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend3', name=f'{alg} agent {i}'), row=3, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_trad'][:, i]+rewards[alg]['r_deg'][:, i]+rewards[alg]['r_glob'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend4', name=f'{alg} agent {i}'), row=4, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_trad'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend5', name=f'{alg} agent {i}'), row=5, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_deg'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend6', name=f'{alg} agent {i}'), row=6, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_clipping'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend7', name=f'{alg} agent {i}'), row=7, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_glob'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend8', name=f'{alg} agent {i}'), row=8, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=log[alg]['actions_batteries'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend9', name=f'{alg} agent {i}'), row=9, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=log[alg]['generations'][:, i]-log[alg]['demands'][:, i]-log[alg]['energy_to_batteries'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend13', name=f'{alg} agent {i}'), row=13, col=1)\n",
    "\n",
    "    for alg in [alg for alg in algs if alg not in full_algs]:\n",
    "        fig.add_trace(go.Scatter(x=time, y=log[alg]['soc'].mean(axis=1), line=dict(color='grey', dash=line_styles[alg]), mode='lines', legend='legend3', name=alg), row=3, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_trad'].mean(axis=1) + rewards[alg]['r_deg'].mean(axis=1) + rewards[alg]['r_glob'].mean(axis=1), line=dict(color='grey', dash=line_styles[alg]), mode='lines', legend='legend4', name=alg), row=4, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_trad'].mean(axis=1), line=dict(color='grey', dash=line_styles[alg]), mode='lines', legend='legend5', name=alg), row=5, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_deg'].mean(axis=1), line=dict(color='grey', dash=line_styles[alg]), mode='lines', legend='legend6', name=alg), row=6, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_clipping'].mean(axis=1), line=dict(color='grey', dash=line_styles[alg]), mode='lines', legend='legend7', name=alg), row=7, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_glob'].mean(axis=1), line=dict(color='grey', dash=line_styles[alg]), mode='lines', legend='legend8', name=alg), row=8, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=log[alg]['actions_batteries'].mean(axis=1), line=dict(color='grey', dash=line_styles[alg]), mode='lines', legend='legend9', name=alg), row=9, col=1)\n",
    "\n",
    "    print(log[alg]['actions_rec'][0].shape, time.shape)\n",
    "\n",
    "    for alg in algs:\n",
    "        for i in range(demands.shape[1]):\n",
    "            fig.add_trace(go.Scatter(x=time, y=log[alg]['actions_rec'][:, i], line=dict(color=colors[i], dash=line_styles[alg]), mode='lines', legend='legend10', name=alg), row=10, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[alg]['r_rec'], line=dict(color='grey', dash=line_styles[alg]), mode='lines', legend='legend11', name=alg), row=11, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=log[alg]['balance_plus']-log[alg]['balance_minus'], line=dict(color='green', dash=line_styles[alg]), mode='lines', legend='legend12', name=alg), row=12, col=1)\n",
    "        # fig.add_trace(go.Scatter(x=time, y=log[alg]['balance_minus'], line=dict(color='red', dash=line_styles[alg]), mode='lines', legend='legend12', name=alg), row=12, col=1)\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='',\n",
    "        xaxis=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis2=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis3=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis4=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis5=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis6=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis7=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis8=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis9=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis10=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis11=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis12=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis13=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "\n",
    "        yaxis=dict(fixedrange=True, title='Wh', minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis2=dict(fixedrange=True, title='/MWh', minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis3=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis4=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis5=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis6=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis7=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis8=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis9=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis10=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis11=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis12=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis13=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "\n",
    "        height=3000,\n",
    "        width=1200,\n",
    "        legend_tracegroupgap=20\n",
    "    )\n",
    "\n",
    "    # fig.update_layout(\n",
    "    # legends=[\n",
    "    #     dict(x=1.05, y=0.95, tracegroup=\"group1\"),  # Legend for first subplot\n",
    "    #     dict(x=1.05, y=0.60, tracegroup=\"group2\"),  # Legend for second subplot\n",
    "    # ]\n",
    "    # )\n",
    "\n",
    "    fig.update_layout(\n",
    "        legend1=dict(\n",
    "            xref=\"container\",\n",
    "            yref=\"container\",\n",
    "            y=0.6),\n",
    "        legend2=dict(\n",
    "            xref=\"container\",\n",
    "            yref=\"container\",\n",
    "            y=0.1)\n",
    "    )\n",
    "\n",
    "    fig.write_html(directory + '/plots.html')\n",
    "    print(directory + '/plots.html')\n",
    "\n",
    "\n",
    "    display(fig)"
   ],
   "id": "1d760135c7cd03e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# plot_external_data_matplotlib(logs['ppo']['demand'], logs['ppo']['generation'], logs['ppo']['sell_price'], logs['ppo']['buy_price'], start=1000, length_max=200)\n",
    "# algs_to_plot = ['only_market', 'battery_first', 'ppo', 'recurrent_ppo']\n",
    "algs_to_plot = ['battery_first', 'only_market', 'ppo', 'recurrent_ppo']#, 'battery_first']\n",
    "# algs_to_plot = ['ppo']      # ['only_market', 'ppo', 'recurrent_ppo']\n",
    "full_algs = ['ppo', 'recurrent_ppo'] #['battery_first', 'only_market', 'recurrent_ppo']#, 'battery_first'] #['ppo']      #['only_market', 'ppo', 'recurrent_ppo']\n",
    "\n",
    "dem_agent = algs_to_plot[0] # 'recurrent_ppo'\n",
    "\n",
    "plot_data_plotly(logs[dem_agent]['demands'], logs[dem_agent]['generations'], logs[dem_agent]['sell_prices'], logs[dem_agent]['buy_prices'], logs, algs_to_plot, full_algs, env.env_step, reward_type='weig_reward', cumulative=False)"
   ],
   "id": "659a3e837f9d1b4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def plot_data_matplotlib(demands, generations, sell_prices, buy_prices, log, algs, full_algs, time_step, reward_type='weig_reward', cumulative=True):\n",
    "    n_points = max(demands.shape[0], generations.shape[0], sell_prices.shape[0], buy_prices.shape[0])\n",
    "    time = pd.date_range('2015-01-01', periods=n_points, freq=str(int(time_step))+'s')\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=11, ncols=1, figsize=(12, 30), sharex=True)\n",
    "    titles = [\"Power demand and generation\", \"Market prices\", \"SoC\", \"Total reward\", \"Trading reward\",\n",
    "              \"Degradation reward\", \"Clipping reward\", \"Global reward\", \"Actions\", \"REC reward\", \"REC balances\"]\n",
    "\n",
    "    for ax, title in zip(axes, titles):\n",
    "        ax.set_title(title)\n",
    "\n",
    "    # Plot power demand and generation\n",
    "    for i in range(demands.shape[1]):\n",
    "        axes[0].plot(time, demands[:, i], label=f'demand agent {i}')\n",
    "    axes[0].plot(time, generations[:, 0], color='grey', label='generation')\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Plot market prices\n",
    "    axes[1].plot(time, sell_prices[:, 0] * 1e6, label='Selling prices')\n",
    "    axes[1].plot(time, buy_prices[:, 0] * 1e6, label='Buying prices')\n",
    "    axes[1].legend()\n",
    "\n",
    "    rewards = {alg: {} for alg in algs}\n",
    "\n",
    "    if cumulative:\n",
    "        for alg in algs:\n",
    "            rewards[alg]['r_tot'] = np.cumsum(log[alg]['r_tot'], axis=0)\n",
    "            rewards[alg]['r_trad'] = np.cumsum(log[alg][reward_type]['r_trad'], axis=0)\n",
    "            rewards[alg]['r_deg'] = np.cumsum(log[alg][reward_type]['r_deg'], axis=0)\n",
    "            rewards[alg]['r_clipping'] = np.cumsum(log[alg][reward_type]['r_clipping'], axis=0)\n",
    "            rewards[alg]['r_glob'] = np.cumsum(log[alg]['r_glob'], axis=0)\n",
    "            rewards[alg]['r_rec'] = np.cumsum(log[alg]['rec_reward'])\n",
    "    else:\n",
    "        for alg in algs:\n",
    "            rewards[alg]['r_tot'] = log[alg]['r_tot']\n",
    "            rewards[alg]['r_trad'] = log[alg][reward_type]['r_trad']\n",
    "            rewards[alg]['r_deg'] = log[alg][reward_type]['r_deg']\n",
    "            rewards[alg]['r_clipping'] = log[alg][reward_type]['r_clipping']\n",
    "            rewards[alg]['r_glob'] = log[alg]['r_glob']\n",
    "            rewards[alg]['r_rec'] = log[alg]['rec_reward']\n",
    "\n",
    "    for alg in full_algs:\n",
    "        for i in range(demands.shape[1]):\n",
    "            axes[2].plot(time, log[alg]['soc'][:, i], label=f'{alg} agent {i}')\n",
    "            axes[3].plot(time, rewards[alg]['r_tot'][:, i], label=f'{alg} agent {i}')\n",
    "            axes[4].plot(time, rewards[alg]['r_trad'][:, i], label=f'{alg} agent {i}')\n",
    "            axes[5].plot(time, rewards[alg]['r_deg'][:, i], label=f'{alg} agent {i}')\n",
    "            axes[6].plot(time, rewards[alg]['r_clipping'][:, i], label=f'{alg} agent {i}')\n",
    "            axes[7].plot(time, rewards[alg]['r_glob'][:, i], label=f'{alg} agent {i}')\n",
    "            axes[8].plot(time, log[alg]['actions_batteries'][:, i], label=f'{alg} agent {i}')\n",
    "\n",
    "    for alg in [alg for alg in algs if alg not in full_algs]:\n",
    "        axes[2].plot(time, log[alg]['soc'].mean(axis=1), label=alg)\n",
    "        axes[3].plot(time, rewards[alg]['r_tot'].mean(axis=1), label=alg)\n",
    "        axes[4].plot(time, rewards[alg]['r_trad'].mean(axis=1), label=alg)\n",
    "        axes[5].plot(time, rewards[alg]['r_deg'].mean(axis=1), label=alg)\n",
    "        axes[6].plot(time, rewards[alg]['r_clipping'].mean(axis=1), label=alg)\n",
    "        axes[7].plot(time, rewards[alg]['r_glob'].mean(axis=1), label=alg)\n",
    "        axes[8].plot(time, log[alg]['actions_batteries'].mean(axis=1), label=alg)\n",
    "\n",
    "    for alg in algs:\n",
    "        axes[9].plot(time, rewards[alg]['r_rec'], label=alg)\n",
    "        axes[10].plot(time, log[alg]['balance_plus'], color='green', label=f'{alg} balance_plus')\n",
    "        axes[10].plot(time, log[alg]['balance_minus'], color='red', label=f'{alg} balance_minus')\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.legend()\n",
    "\n",
    "    plt.xlabel('Time')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "76075c3552556573"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "time_limit = 1000\n",
    "\n",
    "algs_to_plot = ['only_market', 'battery_first', 'ppo', 'recurrent_ppo']\n",
    "# algs_to_plot = ['ppo']      # ['only_market', 'ppo', 'recurrent_ppo']\n",
    "full_algs = [] #['ppo']      #['only_market', 'ppo', 'recurrent_ppo']\n",
    "\n",
    "log_slice = jax.tree.map(lambda x: x[:time_limit], logs)\n",
    "plot_data_matplotlib(log_slice['ppo']['demands'], log_slice['ppo']['generations'], log_slice['ppo']['sell_prices'], log_slice['ppo']['buy_prices'], log_slice, algs_to_plot, full_algs, env.env_step, reward_type='weig_reward')"
   ],
   "id": "60c9aad966598ed9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# plot_ext_data_and_reward_plotly(logs['ppo']['demand'], logs['ppo']['generation'], logs['ppo']['sell_price'], logs['ppo']['buy_price'], logs, algs_to_plot, env.params.env_step)",
   "id": "2a81de0d5a6a5f2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# plot_details_reward_plotly(logs, algs_to_plot, env.params.env_step)",
   "id": "da15f4312e31ec03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "summary = {}\n",
    "\n",
    "for alg in algs:\n",
    "    summary[alg] = {'mean_soc': np.mean(logs[alg]['soc']),\n",
    "                    'r_tot': np.sum(logs[alg]['r_tot']),\n",
    "                    # 'norm_reward': {'r_trad': np.sum(logs[alg]['norm_reward']['r_trad']),\n",
    "                    #                 # 'r_op': np.sum(logs[alg]['norm_reward']['r_op']),\n",
    "                    #                 'r_deg': np.sum(logs[alg]['norm_reward']['r_deg']),\n",
    "                    #                 'r_clipping': np.sum(logs[alg]['norm_reward']['r_clipping'])},\n",
    "                    'weig_reward': {'r_trad': np.sum(logs[alg]['weig_reward']['r_trad']),\n",
    "                                    # 'r_op': np.sum(logs[alg]['weig_reward']['r_op']),\n",
    "                                    'r_deg': np.sum(logs[alg]['weig_reward']['r_deg']),\n",
    "                                    'r_clipping': np.sum(logs[alg]['weig_reward']['r_clipping'])},\n",
    "                    'pure_reward': {'r_trad': np.sum(logs[alg]['pure_reward']['r_trad']),\n",
    "                                    # 'r_op': np.sum(logs[alg]['pure_reward']['r_op']),\n",
    "                                    'r_deg': np.sum(logs[alg]['pure_reward']['r_deg']),\n",
    "                                    'r_clipping': np.sum(logs[alg]['pure_reward']['r_clipping'])},\n",
    "                    'mean_action': np.mean(logs[alg]['actions']),\n",
    "                    'max_action': np.max(logs[alg]['actions']),\n",
    "                    'min_action': np.min(logs[alg]['actions']),\n",
    "                    'variance_action': np.var(logs[alg]['actions']),\n",
    "                    'final_soh': logs[alg]['soh'][-1],}\n",
    "\n",
    "flatten_summary = {}\n",
    "\n",
    "for alg in algs:\n",
    "    flatten_summary[alg] = {}\n",
    "    for key in summary[alg].keys():\n",
    "        if isinstance(summary[alg][key], dict):\n",
    "            flatten_summary[alg].update([(key+'.'+subkey, summary[alg][key][subkey]) for subkey in summary[alg][key].keys()])\n",
    "        else:\n",
    "            flatten_summary[alg][key] = summary[alg][key]\n"
   ],
   "id": "730cb3e5b17b3e0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.DataFrame.from_dict(flatten_summary, orient='index')\n",
    "pd.set_option('display.max_columns', None)\n",
    "df"
   ],
   "id": "9fdb1f143daaf78e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plt.plot(logs['only_market']['soh'][:int(len(logs['ppo']['soh'])/14)])",
   "id": "fff6f4ee0ae64d2b"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
