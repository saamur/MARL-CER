{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%cd ../.."
   ],
   "id": "20cf4644bf6f6dc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '.2'\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from algorithms.tqdm_custom import scan_tqdm\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly\n",
    "import seaborn as sns\n",
    "\n",
    "from plotly_resampler import register_plotly_resampler, FigureWidgetResampler\n",
    "# register_plotly_resampler(mode=\"auto\", default_n_shown_samples=4500)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from algorithms.utils import restore_state, restore_state_multi_agent\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import flax.nnx as nnx\n",
    "from flax.core.frozen_dict import freeze\n",
    "# jax.config.update(\"jax_enable_x64\", True)\n"
   ],
   "id": "aab19cee096af8fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ernestogym.envs.multi_agent.env import RECEnv\n",
    "# from ernestogym.envs.single_agent.env_trading_soc import MicroGridEnvSocAction"
   ],
   "id": "c27cdee3094285da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def my_env_creator(params, battery_type, env_type='normal'):\n",
    "    if env_type == 'normal':\n",
    "        env = RECEnv(params, battery_type)\n",
    "    return env"
   ],
   "id": "4d4959d7f73495bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def print_heatmap(X, Y, Z, num_bins=10, x_label='', y_label='', title='', n_decimals_axes=0):\n",
    "    z_grid, y_edges, x_edges = np.histogram2d(Y, X, bins=(num_bins, num_bins), weights=Z)\n",
    "    counts, _, _ = np.histogram2d(Y, X, bins=(num_bins, num_bins))\n",
    "\n",
    "    z_grid = np.divide(z_grid, counts, out=np.full_like(z_grid, fill_value=np.nan), where=counts > 0)\n",
    "\n",
    "    x_centers = (x_edges[1:]+x_edges[:-1])/2\n",
    "    y_centers = (y_edges[1:]+y_edges[:-1])/2\n",
    "\n",
    "    x_ticks = [f'{v:.{n_decimals_axes}f}' for v in x_centers]\n",
    "    y_ticks = [f'{v:.{n_decimals_axes}f}' for v in y_centers]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(z_grid, xticklabels=x_ticks, yticklabels=y_ticks, cmap='coolwarm', center=0).invert_yaxis()\n",
    "\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_heatmap(X, Y, Z, num_bins=10, x_label='', y_label='', title='', n_decimals_axes=0, ax=None, print_axes=False, annot=True, file_path=None):\n",
    "    z_grid, y_edges, x_edges = np.histogram2d(Y, X, bins=(num_bins, num_bins), weights=Z)\n",
    "    counts, _, _ = np.histogram2d(Y, X, bins=(num_bins, num_bins))\n",
    "\n",
    "    z_grid = np.divide(z_grid, counts, out=np.full_like(z_grid, fill_value=np.nan), where=counts > 0)\n",
    "\n",
    "    x_centers = (x_edges[1:]+x_edges[:-1])/2\n",
    "    y_centers = (y_edges[1:]+y_edges[:-1])/2\n",
    "\n",
    "    x_ticks = [f'{v:.{n_decimals_axes}f}' for v in x_centers]\n",
    "    y_ticks = [f'{v:.{n_decimals_axes}f}' for v in y_centers]\n",
    "\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    if annot:\n",
    "        sns.heatmap(z_grid, annot=counts, annot_kws={\"fontsize\":8}, xticklabels=x_ticks, yticklabels=y_ticks, cmap='coolwarm', center=0, robust=True, ax=ax)\n",
    "    else:\n",
    "        sns.heatmap(z_grid, xticklabels=x_ticks, yticklabels=y_ticks, cmap='coolwarm', center=0, robust=True, ax=ax)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    if print_axes:\n",
    "        x_zero_index = np.searchsorted(x_centers, 0)\n",
    "        y_zero_index = np.searchsorted(y_centers, 0)\n",
    "\n",
    "        if 0 <= x_zero_index < len(x_edges):\n",
    "            ax.axvline(x=x_zero_index, color='green', linewidth=2)\n",
    "        if 0 <= y_zero_index < len(y_edges):\n",
    "            ax.axhline(y=y_zero_index, color='green', linewidth=2)\n",
    "\n",
    "\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    if file_path is not None:\n",
    "        plt.savefig(file_path, bbox_inches='tight')\n",
    "\n",
    "def plot_hist_soc(soc, actions):\n",
    "    hist, bins = np.histogram(soc, weights=actions, bins=16)\n",
    "    counts, _ = np.histogram(soc, bins=16)\n",
    "\n",
    "    hist = np.divide(hist, counts, where=counts > 0)\n",
    "\n",
    "    bins_ctrs = (bins[:-1] + bins[1:])/2\n",
    "\n",
    "    plt.bar(bins_ctrs, hist, width=0.045)\n",
    "\n",
    "    plt.xlabel('SoC')\n",
    "    plt.ylabel('Mean action')"
   ],
   "id": "5c315f597debea44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from ernestogym.envs.multi_agent.utils import get_world_data",
   "id": "8d29251f3e6349d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b3b0354738436a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "num_iter = 8760 * 5",
   "id": "d24b070c04614ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing",
   "id": "defbda0e8ef0fd1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "logs = {}\n",
    "experiments = []\n",
    "agents = {}"
   ],
   "id": "cb88bc7b52d17dc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@partial(jax.jit, static_argnums=(0, 1, 2, 3, 4, 6))\n",
    "def test(env:RECEnv, networks_batteries, network_rec, num_iter, config, rng, rec_rule_based_policy):\n",
    "\n",
    "    networks_batteries.eval()\n",
    "    if not config['USE_REC_RULE_BASED_POLICY']:\n",
    "        network_rec.eval()\n",
    "\n",
    "    rng, _rng = jax.random.split(rng)\n",
    "\n",
    "    obsv, env_state = env.reset(_rng, profile_index=0)\n",
    "\n",
    "    if config['NETWORK_TYPE_BATTERIES'] == 'recurrent_actor_critic' and config['NUM_RL_AGENTS'] > 0:\n",
    "        init_act_state_batteries, init_cri_state_batteries = networks_batteries.get_initial_lstm_state()\n",
    "        act_state_batteries, cri_state_batteries = init_act_state_batteries, init_cri_state_batteries\n",
    "    else:\n",
    "        act_state_batteries, cri_state_batteries = None, None\n",
    "\n",
    "    if not config['USE_REC_RULE_BASED_POLICY'] and config['NETWORK_TYPE_REC'] == 'recurrent_actor_critic':\n",
    "        init_act_state_rec, init_cri_state_rec = network_rec.get_initial_lstm_state()\n",
    "        act_state_rec, cri_state_rec = init_act_state_rec, init_cri_state_rec\n",
    "    else:\n",
    "        act_state_rec, cri_state_rec = None, None\n",
    "\n",
    "    @scan_tqdm(0, 0, 1, num_iter, print_rate=num_iter // 100)\n",
    "    def _env_step(runner_state, unused):\n",
    "        obsv_batteries, env_state, act_state_batteries, act_state_rec, rec_cri_separate, rng, next_profile_index = runner_state\n",
    "\n",
    "        # print('aaaaa', obsv_batteries[:config['NUM_RL_AGENTS']].shape)\n",
    "\n",
    "        actions_batteries = []\n",
    "\n",
    "        if config['NUM_RL_AGENTS'] > 0:\n",
    "\n",
    "            obsv_batteries_rl = obsv_batteries[:config['NUM_RL_AGENTS']]\n",
    "            if config['VALUES_IN_OBS_SPACE']:\n",
    "                obsv_batteries_rl = jnp.concat((obsv_batteries_rl, rec_cri_separate[:config['NUM_RL_AGENTS']]), axis=-1)\n",
    "                obsv_only_cri = None\n",
    "            else:\n",
    "                obsv_only_cri = rec_cri_separate[:config['NUM_RL_AGENTS']]\n",
    "\n",
    "            if config['NETWORK_TYPE_BATTERIES'] == 'recurrent_actor_critic':\n",
    "                pi, _, act_state_batteries, _ = networks_batteries(obsv_batteries_rl, act_state_batteries, cri_state_batteries)\n",
    "            else:\n",
    "                pi, value_batteries = networks_batteries(obsv_batteries_rl, obsv_only_cri)\n",
    "\n",
    "            #deterministic action\n",
    "            actions_batteries_rl = pi.mode()\n",
    "\n",
    "            # print('act 1', actions_batteries_rl.shape)\n",
    "            actions_batteries_rl = actions_batteries_rl.squeeze(axis=-1)\n",
    "            actions_batteries.append(actions_batteries_rl)\n",
    "\n",
    "\n",
    "        if config['NUM_BATTERY_FIRST_AGENTS'] > 0:\n",
    "            idx_start_bf = config['NUM_RL_AGENTS']\n",
    "            idx_end_bf = config['NUM_RL_AGENTS'] + config['NUM_BATTERY_FIRST_AGENTS']\n",
    "\n",
    "            demand = obsv_batteries[idx_start_bf:idx_end_bf, env._obs_battery_agents_idx['demand']]\n",
    "            generation = obsv_batteries[idx_start_bf:idx_end_bf, env._obs_battery_agents_idx['generation']]\n",
    "\n",
    "            actions_batteries_battery_first = (generation - demand) / env_state.battery_states.electrical_state.v[idx_start_bf:idx_end_bf]\n",
    "\n",
    "            actions_batteries.append(actions_batteries_battery_first)\n",
    "\n",
    "        if config['NUM_ONLY_MARKET_AGENTS'] > 0:\n",
    "            actions_batteries_only_market = jnp.zeros(\n",
    "                (config['NUM_ONLY_MARKET_AGENTS'],))\n",
    "            actions_batteries.append(actions_batteries_only_market)\n",
    "\n",
    "        if config['NUM_RANDOM_AGENTS'] > 0:\n",
    "            rng, _rng = jax.random.split(rng)\n",
    "            idx_start_random = config['NUM_RL_AGENTS'] + config['NUM_BATTERY_FIRST_AGENTS'] + config[\n",
    "                'NUM_ONLY_MARKET_AGENTS']\n",
    "\n",
    "            actions_batteries_random = jax.random.uniform(_rng,\n",
    "                                                          shape=(config['NUM_RANDOM_AGENTS'],),\n",
    "                                                          minval=-1.,\n",
    "                                                          maxval=1.)\n",
    "\n",
    "            actions_batteries_random *= config['MAX_ACTION_RANDOM_AGENTS']\n",
    "\n",
    "            actions_batteries.append(actions_batteries_random)\n",
    "\n",
    "        actions_batteries = jnp.concat(actions_batteries, axis=0)\n",
    "\n",
    "\n",
    "        actions_first = {env.battery_agents[i]: actions_batteries[i] for i in range(env.num_battery_agents)}\n",
    "        actions_first[env.rec_agent] = jnp.zeros(env.num_battery_agents)\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state, reward_first, done_first, info_first = env.step(\n",
    "            _rng, env_state, actions_first\n",
    "        )\n",
    "\n",
    "        rec_obsv = obsv[env.rec_agent]\n",
    "\n",
    "        if config['NUM_RL_AGENTS'] < config['NUM_BATTERY_AGENTS']:\n",
    "            values_batteries_for_rec = jnp.concat((value_batteries, jnp.zeros(config['NUM_BATTERY_AGENTS'] - config['NUM_RL_AGENTS'])))\n",
    "        else:\n",
    "            values_batteries_for_rec = value_batteries\n",
    "\n",
    "        rec_obsv['values_batteries'] = values_batteries_for_rec\n",
    "\n",
    "        if not config['USE_REC_RULE_BASED_POLICY']:\n",
    "            if config['NETWORK_TYPE_REC'] == 'recurrent_actor_critic':\n",
    "                pi, _, act_state_rec, _ = network_rec(rec_obsv, act_state_rec, cri_state_rec)\n",
    "            else:\n",
    "                pi, _, separate_cri = network_rec(rec_obsv, return_separate_cri=True)\n",
    "                separate_cri = jnp.expand_dims(separate_cri, -1)\n",
    "            actions_rec = pi.mean()\n",
    "        else:\n",
    "            actions_rec = rec_rule_based_policy(rec_obsv)\n",
    "\n",
    "        actions_second = {agent: jnp.array(0.) for agent in env.battery_agents}\n",
    "        actions_second[env.rec_agent] = actions_rec\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state, reward_second, done_second, info_second = env.step(\n",
    "            _rng, env_state, actions_second\n",
    "        )\n",
    "\n",
    "        done = jnp.logical_or(done_first['__all__'], done_second['__all__'])\n",
    "\n",
    "        info = jax.tree.map(lambda  x, y: x + y, info_first, info_second)\n",
    "\n",
    "        info['actions_batteries'] = actions_batteries\n",
    "        info['actions_rec'] = actions_rec\n",
    "        info['dones'] = jax.tree.map(lambda x, y : jnp.logical_or(x, y), done_first, done_second)\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obsv, env_state,next_profile_index = jax.lax.cond(done,\n",
    "                                                          lambda : env.reset(_rng, profile_index=next_profile_index) + (next_profile_index+1,),\n",
    "                                                          lambda : (obsv, env_state, next_profile_index))\n",
    "\n",
    "        # jax.lax.cond(done, lambda: jax.debug.print('i {x}, {dem}, {gen}, {spr}, {bpr}, {rew}, {pr}, {nr}, {wr}\\n{soh}\\n',\n",
    "        #                                            x=unused, dem=info['demands'], gen=info['generations'],\n",
    "        #                                            spr=info['sell_prices'], bpr=info['buy_prices'], rew=info['r_tot'],\n",
    "        #                                            pr=info['pure_reward'], nr=info['norm_reward'], wr=info['weig_reward'],\n",
    "        #                                            soh=info['soh'], ordered=True), lambda : None)\n",
    "\n",
    "        obs_batteries = jnp.vstack([obsv[a] for a in env.battery_agents])\n",
    "\n",
    "        runner_state = (obs_batteries, env_state, act_state_batteries, act_state_rec, separate_cri, rng, next_profile_index)\n",
    "        return runner_state, info\n",
    "\n",
    "    obsv_batteries = jnp.vstack([obsv[a] for a in env.battery_agents])\n",
    "\n",
    "    runner_state = (obsv_batteries, env_state, act_state_batteries, act_state_rec, jnp.zeros((config['NUM_BATTERY_AGENTS'], 1)), rng, 1)\n",
    "\n",
    "    runner_state, info = jax.lax.scan(_env_step, runner_state, jnp.arange(num_iter))\n",
    "\n",
    "    return info"
   ],
   "id": "f65b5dfb78e7d925"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def rec_scarce_resource_policy(rec_obs):\n",
    "    net_exchange = rec_obs['generations_battery_houses'] - rec_obs['demands_base_battery_houses'] - rec_obs['demands_battery_battery_houses']\n",
    "\n",
    "    net_exchange_plus = jnp.maximum(net_exchange, 0)\n",
    "    net_exchange_minus = -jnp.minimum(net_exchange, 0)\n",
    "\n",
    "    action_plus = net_exchange_plus / (net_exchange_plus.sum(axis=-1, keepdims=True) + 1e-8)\n",
    "    action_minus = net_exchange_minus / (net_exchange_minus.sum(axis=-1, keepdims=True) + 1e-8)\n",
    "\n",
    "    actions = (rec_obs['network_REC_plus'] > rec_obs['network_REC_minus'])[..., None] * action_minus + (rec_obs['network_REC_plus'] <= rec_obs['network_REC_minus'])[..., None] * action_plus\n",
    "\n",
    "    actions = jnp.where(actions.sum(axis=-1, keepdims=True) == 0., jnp.ones_like(actions)/actions.shape[-1], actions)\n",
    "\n",
    "    # jax.debug.print('{x}', x=actions)\n",
    "\n",
    "    return actions\n",
    "\n",
    "def rec_both_resources_policy(rec_obs):\n",
    "    net_exchange = rec_obs['generations_battery_houses'] - rec_obs['demands_base_battery_houses'] - rec_obs['demands_battery_battery_houses']\n",
    "\n",
    "    net_exchange_plus = jnp.maximum(net_exchange, 0)\n",
    "    net_exchange_minus = -jnp.minimum(net_exchange, 0)\n",
    "\n",
    "    frac_plus = net_exchange_plus / (net_exchange_plus.sum(axis=-1, keepdims=True) + 1e-8)\n",
    "    frac_minus = net_exchange_minus / (net_exchange_minus.sum(axis=-1, keepdims=True) + 1e-8)\n",
    "\n",
    "    actions = (frac_plus + frac_minus) / 2\n",
    "\n",
    "    actions = jnp.where(actions.sum(axis=-1, keepdims=True) == 0., jnp.ones_like(actions) / actions.shape[-1], actions)\n",
    "\n",
    "    return actions"
   ],
   "id": "81019e9920f3a120"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "directory = '/media/samuele/Disco/PycharmProjectsUbuntu/MARL-CER/trained_agents/server_15-16/in_act_too/20250416_002955_bat_net_type_asymmetric_actor_critic_rec_net_type_asymmetric_actor_critic_lr_bat_5e-05_lr_REC_cosine_tot_timesteps_7008000_lr_sched_cosine_multiagent'\n",
    "\n",
    "curr_exp = 'exp1'\n",
    "experiments.append(curr_exp)\n",
    "\n",
    "networks_batteries, network_rec, config, world_metadata, train_info, val_info = restore_state_multi_agent(directory)\n",
    "\n",
    "print(world_metadata)\n",
    "\n",
    "test_params = get_world_data(world_metadata, get_test=True)\n",
    "battery_type = 'degrading_dropflow'\n",
    "\n",
    "curr_agents = []\n",
    "curr_agents += ['recurrent_ppo_agent_' if config['NETWORK_TYPE_BATTERIES'] == 'recurrent_actor_critic' else 'ppo_agent_' + str(i) for i in range(config['NUM_RL_AGENTS'])]\n",
    "curr_agents += ['battery_first_agent_' + str(i) for i in range(config['NUM_BATTERY_FIRST_AGENTS'])]\n",
    "curr_agents += ['only_market_agent_' + str(i) for i in range(config['NUM_ONLY_MARKET_AGENTS'])]\n",
    "curr_agents += ['random_agent_' + str(i) for i in range(config['NUM_RANDOM_AGENTS'])]\n",
    "\n",
    "agents[curr_exp] = curr_agents"
   ],
   "id": "5b7eb2ba15e6caf4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "network_rec",
   "id": "bce1068c13c827b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "networks_batteries.log_std",
   "id": "f1b06e5b264bd6ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "config",
   "id": "8e0f32cfa63ea814"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "world_metadata",
   "id": "7aa3f90928af1d54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env = my_env_creator(test_params, battery_type, config['ENV_TYPE'])",
   "id": "9fea2789ff91ab2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from time import time\n",
    "t0 = time()\n",
    "info = test(env, networks_batteries, network_rec, num_iter, freeze(config), jax.random.PRNGKey(51), rec_rule_based_policy=rec_scarce_resource_policy)\n",
    "print(time() - t0)\n",
    "logs[curr_exp] = info"
   ],
   "id": "ced869789471ab4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "info['demands'].shape",
   "id": "db373dff71fda3dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "reward_type = 'pure_reward'",
   "id": "a077315d79a889c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_heatmap(info['demands'][:, :config['NUM_RL_AGENTS']].flatten(), info['generations'][:, :config['NUM_RL_AGENTS']].flatten(), info['actions_batteries'][:, :config['NUM_RL_AGENTS']].flatten(), x_label='Demand', y_label='Generation', title='Actions batteries', file_path=directory+'/actions_rl.png')",
   "id": "b04b872bdf22c24f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "info[reward_type]['r_glob'].mean(), info[reward_type]['r_glob'].max(), info[reward_type]['r_glob'].min()",
   "id": "824dd8060353d9fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "net_exchange = info['generations'] - info['demands'] - info['energy_to_batteries']\n",
    "balance = info['balance_plus'] - info['balance_minus']\n",
    "centered_r_glob = info[reward_type]['r_glob'] - info[reward_type]['r_glob'].mean(axis=1, keepdims=True)\n",
    "\n",
    "print_heatmap(net_exchange[:, :config['NUM_RL_AGENTS']].T.flatten(), np.tile(balance, reps=config['NUM_RL_AGENTS']), centered_r_glob[:, :config['NUM_RL_AGENTS']].T.flatten(), x_label='Network exchange', y_label='Balance', title='Centered global reward', print_axes=True, file_path=directory+'/centered_global_reward_rl.png') #, num_bins=25, annot=False)"
   ],
   "id": "2a02b885c9d47445"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "_, axs = plt.subplots(1, config['NUM_RL_AGENTS'], figsize=(15, 5))\n",
    "\n",
    "if config['NUM_RL_AGENTS'] > 1:\n",
    "    axs = axs.flatten()\n",
    "    for i in range(config['NUM_RL_AGENTS']):\n",
    "        print_heatmap(net_exchange[:, i], balance, centered_r_glob[:, i], ax=axs[i], x_label='Network exchange', y_label='Balance', title=f'Centered global reward agent {i}', print_axes=True)"
   ],
   "id": "863da0bfec6ef2b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "config['NUM_RL_AGENTS'], config['NUM_BATTERY_AGENTS']",
   "id": "d96c8ff9f51b1e3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_heatmap(net_exchange[:, config['NUM_RL_AGENTS']:].T.flatten(), np.tile(balance, reps=config['NUM_BATTERY_AGENTS']-config['NUM_RL_AGENTS']), centered_r_glob[:, config['NUM_RL_AGENTS']:].T.flatten(), x_label='Network exchange', y_label='Balance', title='Centered global reward', print_axes=True, file_path=directory+'/centered_global_reward_rule_based.png') #, num_bins=25)",
   "id": "44807076b905fd32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "net_exchange.shape",
   "id": "dedb6e20a4fa9d36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "centered_net_exchange = net_exchange - net_exchange.mean(axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "print_heatmap(centered_net_exchange[:, :config['NUM_RL_AGENTS']].T.flatten(), np.tile(balance, reps=config['NUM_RL_AGENTS']), centered_r_glob[:, :config['NUM_RL_AGENTS']].T.flatten(), x_label='Centered network exchange', y_label='Balance', title='Centered global reward', print_axes=True, file_path=directory+'/centered_global_reward_with_centered_network_rl.png') #, num_bins=25, annot=False)"
   ],
   "id": "a2192506d1e4156e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "_, axs = plt.subplots(1, config['NUM_RL_AGENTS'], figsize=(15, 5))\n",
    "\n",
    "if config['NUM_RL_AGENTS'] > 1:\n",
    "    axs = axs.flatten()\n",
    "    for i in range(config['NUM_RL_AGENTS']):\n",
    "        print_heatmap(centered_net_exchange[:, i], balance, centered_r_glob[:, i], ax=axs[i], x_label='Network exchange', y_label='Balance', title=f'Centered global reward agent {i}', print_axes=True)"
   ],
   "id": "8b1cd0942eb08a3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_heatmap(centered_net_exchange[:, config['NUM_RL_AGENTS']:].T.flatten(), np.tile(balance, reps=config['NUM_BATTERY_AGENTS']-config['NUM_RL_AGENTS']), centered_r_glob[:, config['NUM_RL_AGENTS']:].T.flatten(), x_label='Network exchange', y_label='Balance', title='Centered global reward', print_axes=True, file_path=directory+'/centered_global_reward_with_centered_network_rule_based.png') #, num_bins=25)",
   "id": "2eeeeb6b17d067dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# print_heatmap(net_exchange[:, :config['NUM_RL_AGENTS']].T.flatten(), np.tile(info['balance_plus'] - info['balance_minus'], reps=config['NUM_RL_AGENTS']), info[reward_type]['r_glob'][:, :config['NUM_RL_AGENTS']].T.flatten(), x_label='Network exchange', y_label='Balance', title='Actions REC')",
   "id": "e6bf15893681992a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# print_heatmap(net_exchange[:, config['NUM_RL_AGENTS']:].T.flatten(), np.tile(info['balance_plus'] - info['balance_minus'], reps=config['NUM_BATTERY_AGENTS']-config['NUM_RL_AGENTS']), info['actions_rec'][:, config['NUM_RL_AGENTS']:].T.flatten(), x_label='Network exchange', y_label='Balance', title='Actions REC')",
   "id": "c1e8d875b7f22e7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_hist_soc(info['soc'].flatten(), info['actions_batteries'].flatten())",
   "id": "599afdabac790d0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plotting",
   "id": "afe2bec4973e65cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "logs = jax.tree.map(lambda x : np.asarray(x), logs)\n",
   "id": "92d416f0e65c3bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "exp = ['exp1']\n",
    "\n",
    "print('Tot self consumption')\n",
    "for e in exp:\n",
    "    print(f'\\t{e}: {np.sum(logs[e]['self_consumption'])}')\n",
    "\n",
    "print('Tot reward')\n",
    "for e in exp:\n",
    "    print(f'\\t{e}: {np.sum(logs[e]['r_tot'])}')\n",
    "\n",
    "print('Tot glob reward')\n",
    "for e in exp:\n",
    "    print(f'\\t{e}: {np.sum(logs[e][reward_type]['r_glob'])}')\n",
    "\n",
    "print('Tot trad reward')\n",
    "for e in exp:\n",
    "    print(f'\\t{e}: {np.sum(logs[e][reward_type]['r_trad'])}')\n",
    "\n",
    "print('Tot deg reward')\n",
    "for e in exp:\n",
    "    print(f'\\t{e}: {np.sum(logs[e][reward_type]['r_deg'])}')\n",
    "\n",
    "print('Tot clipping reward')\n",
    "for e in exp:\n",
    "    print(f'\\t{e}: {np.sum(logs[e][reward_type]['r_clipping'])}')\n",
    "\n",
    "print('Tot rec reward')\n",
    "for e in exp:\n",
    "    print(f'\\t{e}: {np.sum(logs[e]['rec_reward'])}')\n",
    "\n",
    "print('Ratios global reward')\n",
    "for e in exp:\n",
    "    glob_rew = logs[e][reward_type]['r_glob'].sum(axis=0)\n",
    "    print(f'\\t{e}: {glob_rew/glob_rew.sum()}')\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Mean rec actions')\n",
    "for e in exp:\n",
    "    print(f'\\t{e}: {np.mean(logs[e]['actions_rec'], axis=0)}')\n",
    "print('Mean of variance rec actions')\n",
    "for e in exp:\n",
    "    print(f'\\t{e}: {np.mean(np.var(logs[e]['actions_rec'], axis=1))}')\n",
    "print('Mean of difference max-min rec actions')\n",
    "for e in exp:\n",
    "    print(f'\\t{e}: {np.mean(np.max(logs[e]['actions_rec'], axis=1) - np.min(logs[e]['actions_rec'], axis=1))}')\n",
    "\n",
    "print('Pearson correlation coeff')\n",
    "for e in exp:\n",
    "    v1 = logs[e]['actions_rec']\n",
    "    v2 = (logs[e]['generations']-logs[e]['demands']-logs[e]['energy_to_batteries']) * (logs[e]['balance_plus'] - logs[e]['balance_minus'])[:, None]\n",
    "    coeff = np.mean((v1 - v1.mean(axis=0, keepdims=True)) * (v2 - v2.mean(axis=0, keepdims=True)), axis=0)\n",
    "    norm_coeff = coeff/np.sqrt(np.var(v1, axis=0)*np.var(v2, axis=0))\n",
    "    print(f'\\t{e}: {coeff}\\t\\t{norm_coeff}')\n"
   ],
   "id": "fd574de21b877925"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "e = 'exp1'\n",
    "\n",
    "a = logs[e]['actions_rec'][:, :config['NUM_RL_AGENTS']].T.flatten()\n",
    "\n",
    "b = (logs[e]['generations'][:, :config['NUM_RL_AGENTS']]-logs[e]['demands'][:, :config['NUM_RL_AGENTS']]-logs[e]['energy_to_batteries'][:, :config['NUM_RL_AGENTS']]).T.flatten()\n",
    "c = np.tile(logs[e]['balance_plus'] - logs[e]['balance_minus'], reps=config['NUM_RL_AGENTS'])\n",
    "\n",
    "print(np.corrcoef(b, c)[0, 1])\n",
    "\n",
    "X = np.column_stack((b, c, b * c))  # Independent variables\n",
    "X = sm.add_constant(X)  # Add intercept\n",
    "model = sm.OLS(a, X).fit()\n",
    "\n",
    "print(model.summary())"
   ],
   "id": "2710b5f5594a9eea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "X = np.column_stack((b, c, b * c))\n",
    "vif = [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "print(vif)"
   ],
   "id": "da3566b09820d53e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "v1 = logs['exp1']['actions_rec'][:, 0]\n",
    "v2 = (logs['exp1']['generations'][:, 0]-logs['exp1']['demands'][:, 0]-logs['exp1']['energy_to_batteries'][:, 0]) * (logs['exp1']['balance_plus'] - logs['exp1']['balance_minus'])\n",
    "\n",
    "print(np.corrcoef(v1, v2))\n",
    "\n",
    "print(v1.shape)\n",
    "print(v2.shape)\n",
    "\n",
    "\n",
    "np.mean((v1-v1.mean()) * (v2-v2.mean())) / np.sqrt(np.var(v1)*np.var(v2))"
   ],
   "id": "9cf94ac0afc79038"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# exp = ['random', 'only_market', 'battery_first', 'ppo', 'recurrent_ppo']        #, 'recurrent_ppo']\n",
    "# colors = {e: col for e, col in zip(es, plotly.colors.sample_colorscale('rainbow', len(es)))}\n",
    "colors = plotly.colors.sample_colorscale('rainbow', env.num_battery_agents)\n",
    "line_styles = {'exp1': 'solid'}\n",
    "\n",
    "def plot_data_plotly(demands, generations, sell_prices, buy_prices, log, exp, full_exp, agents, time_step, reward_type='weig_reward', cumulative=True):\n",
    "\n",
    "    n_points = max(demands.shape[0], generations.shape[0], sell_prices.shape[0], buy_prices.shape[0])\n",
    "    # print(n_points)\n",
    "    # print(demands.shape)\n",
    "\n",
    "    time = pd.date_range('2015-01-01', periods=n_points, freq=str(int(time_step))+'s')\n",
    "    # fig = FigureWidgetResampler(make_subplots(rows=11, cols=1, shared_xaxes=True, vertical_spacing = 0.02, subplot_titles=['Power demand and generation', 'SoC', 'Trad plus deg plus glob reward', 'Trading reward', 'Degradation reward', 'Global reward', 'Actions', 'REC actions', 'REC reward','REC balances', 'Network exchange']), default_n_shown_samples=5000)\n",
    "\n",
    "    fig = make_subplots(rows=11, cols=1, shared_xaxes=True, vertical_spacing = 0.02, subplot_titles=['Power demand and generation', 'SoC', 'Trad plus deg plus glob reward', 'Trading reward', 'Degradation reward', 'Global reward', 'Actions', 'REC actions', 'REC reward','REC balances', 'Network exchange'])\n",
    "    # fig = make_subplots(rows=11, cols=1, shared_xaxes=True, vertical_spacing = 0.05, subplot_titles=['Power demand and generation', 'Market prices', 'SoC', 'Total reward', 'Trading reward', 'Degradation reward', 'Clipping reward', 'Global reward', 'Actions', 'REC reward', 'REC balances'])\n",
    "\n",
    "    # print(time.shape)\n",
    "    # print(demands[: 0].shape)\n",
    "\n",
    "    for i in range(demands.shape[1]):\n",
    "        fig.add_trace(go.Scatter(x=time, y=demands[:, i], mode='lines', legend='legend1', name=f'demand {agents[exp[0]][i]}', line=dict(color=colors[i], dash='solid')), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=generations[:, i], mode='lines', legend='legend1', name=f'generation  {agents[exp[0]][i]}', line=dict(color=colors[i], dash='dot')), row=1, col=1)\n",
    "\n",
    "    rewards = {}\n",
    "    for e in exp:\n",
    "        rewards[e] = {}\n",
    "\n",
    "    if cumulative:\n",
    "        for e in exp:\n",
    "            rewards[e]['r_tot'] = np.cumsum(log[e]['r_tot'], axis=0)\n",
    "            rewards[e]['r_trad'] = np.cumsum(log[e][reward_type]['r_trad'], axis=0)\n",
    "            rewards[e]['r_deg'] = np.cumsum(log[e][reward_type]['r_deg'], axis=0)\n",
    "            rewards[e]['r_clipping'] = np.cumsum(log[e][reward_type]['r_clipping'], axis=0)\n",
    "            rewards[e]['r_glob'] = np.cumsum(log[e][reward_type]['r_glob'], axis=0)\n",
    "            rewards[e]['r_rec'] = np.cumsum(log[e]['rec_reward'])\n",
    "    else:\n",
    "        for e in exp:\n",
    "            rewards[e]['r_tot'] = log[e]['r_tot']\n",
    "            rewards[e]['r_trad'] = log[e][reward_type]['r_trad']\n",
    "            rewards[e]['r_deg'] = log[e][reward_type]['r_deg']\n",
    "            rewards[e]['r_clipping'] = log[e][reward_type]['r_clipping']\n",
    "            rewards[e]['r_glob'] = log[e][reward_type]['r_glob']\n",
    "            rewards[e]['r_rec'] = log[e]['rec_reward']\n",
    "\n",
    "    for e in full_exp:\n",
    "        for i in range(demands.shape[1]):\n",
    "            fig.add_trace(go.Scatter(x=time, y=log[e]['soc'][:, i], line=dict(color=colors[i], dash=line_styles[e]), mode='lines', legend='legend2', name=f'{e} {agents[e][i]}'), row=2, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_trad'][:, i]+rewards[e]['r_deg'][:, i]+rewards[e]['r_glob'][:, i], line=dict(color=colors[i], dash=line_styles[e]), mode='lines', legend='legend3', name=f'{e} {agents[e][i]}'), row=3, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_trad'][:, i], line=dict(color=colors[i], dash=line_styles[e]), mode='lines', legend='legend4', name=f'{e} {agents[e][i]}'), row=4, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_deg'][:, i], line=dict(color=colors[i], dash=line_styles[e]), mode='lines', legend='legend5', name=f'{e} {agents[e][i]}'), row=5, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_glob'][:, i], line=dict(color=colors[i], dash=line_styles[e]), mode='lines', legend='legend6', name=f'{e} {agents[e][i]}'), row=6, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=log[e]['actions_batteries'][:, i], line=dict(color=colors[i], dash=line_styles[e]), mode='lines', legend='legend7', name=f'{e} {agents[e][i]}'), row=7, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=log[e]['generations'][:, i]-log[e]['demands'][:, i]-log[e]['energy_to_batteries'][:, i], line=dict(color=colors[i], dash=line_styles[e]), mode='lines', legend='legend11', name=f'{e} {agents[e][i]}'), row=11, col=1)\n",
    "\n",
    "    for e in [e for e in exp if e not in full_exp]:\n",
    "        fig.add_trace(go.Scatter(x=time, y=log[e]['soc'].mean(axis=1), line=dict(color='grey', dash=line_styles[e]), mode='lines', legend='legend2', name=e), row=2, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_trad'].mean(axis=1) + rewards[e]['r_deg'].mean(axis=1) + rewards[e]['r_glob'].mean(axis=1), line=dict(color='grey', dash=line_styles[e]), mode='lines', legend='legend3', name=e), row=3, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_trad'].mean(axis=1), line=dict(color='grey', dash=line_styles[e]), mode='lines', legend='legend4', name=e), row=4, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_deg'].mean(axis=1), line=dict(color='grey', dash=line_styles[e]), mode='lines', legend='legend5', name=e), row=5, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_glob'].mean(axis=1), line=dict(color='grey', dash=line_styles[e]), mode='lines', legend='legend6', name=e), row=6, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=log[e]['actions_batteries'].mean(axis=1), line=dict(color='grey', dash=line_styles[e]), mode='lines', legend='legend7', name=e), row=7, col=1)\n",
    "\n",
    "    print(log[e]['actions_rec'][0].shape, time.shape)\n",
    "\n",
    "    for e in exp:\n",
    "        for i in range(demands.shape[1]):\n",
    "            fig.add_trace(go.Scatter(x=time, y=log[e]['actions_rec'][:, i], line=dict(color=colors[i], dash=line_styles[e]), mode='lines', legend='legend8', name=e), row=8, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_rec'], line=dict(color='grey', dash=line_styles[e]), mode='lines', legend='legend9', name=e), row=9, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=log[e]['balance_plus'], line=dict(color='green', dash=line_styles[e]), mode='lines', legend='legend10', name=e), row=10, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=log[e]['balance_minus'], line=dict(color='red', dash=line_styles[e]), mode='lines', legend='legend10', name=e), row=10, col=1)\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='',\n",
    "        xaxis=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis2=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis3=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis4=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis5=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis6=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis7=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis8=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis9=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis10=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis11=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "\n",
    "        yaxis=dict(fixedrange=True, title='Wh', minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis2=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis3=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis4=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis5=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis6=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis7=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis8=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis9=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis10=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis11=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "\n",
    "        height=3000,\n",
    "        width=1200,\n",
    "        legend_tracegroupgap=20\n",
    "    )\n",
    "\n",
    "    # fig.update_layout(\n",
    "    # legends=[\n",
    "    #     dict(x=1.05, y=0.95, tracegroup=\"group1\"),  # Legend for first subplot\n",
    "    #     dict(x=1.05, y=0.60, tracegroup=\"group2\"),  # Legend for second subplot\n",
    "    # ]\n",
    "    # )\n",
    "\n",
    "    fig.update_layout(\n",
    "        legend1=dict(\n",
    "            xref=\"container\",\n",
    "            yref=\"container\",\n",
    "            y=0.6),\n",
    "        legend2=dict(\n",
    "            xref=\"container\",\n",
    "            yref=\"container\",\n",
    "            y=0.1)\n",
    "    )\n",
    "\n",
    "\n",
    "    fig.write_html(directory + '/plots.html')\n",
    "    fig = FigureWidgetResampler(fig, default_n_shown_samples=5000)\n",
    "    print(directory + '/plots.html')\n",
    "\n",
    "\n",
    "    display(fig)"
   ],
   "id": "73c7371d804ed40b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# plot_external_data_matplotlib(logs['ppo']['demand'], logs['ppo']['generation'], logs['ppo']['sell_price'], logs['ppo']['buy_price'], start=1000, length_max=200)\n",
    "# algs_to_plot = ['only_market', 'battery_first', 'ppo', 'recurrent_ppo']\n",
    "exp_to_plot = ['exp1'] #['battery_first', 'only_market', 'ppo', 'recurrent_ppo']#, 'battery_first']\n",
    "# algs_to_plot = ['ppo']      # ['only_market', 'ppo', 'recurrent_ppo']\n",
    "full_exp = ['exp1'] #['ppo']#, 'recurrent_ppo'] #['battery_first', 'only_market', 'recurrent_ppo']#, 'battery_first'] #['ppo']      #['only_market', 'ppo', 'recurrent_ppo']\n",
    "\n",
    "dem_agent = exp_to_plot[0] # 'recurrent_ppo'\n",
    "\n",
    "plot_data_plotly(logs[dem_agent]['demands'], logs[dem_agent]['generations'], logs[dem_agent]['sell_prices'], logs[dem_agent]['buy_prices'], logs, exp_to_plot, full_exp, agents, env.env_step, reward_type='weig_reward', cumulative=True)"
   ],
   "id": "e846696468df0635"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# exp = ['random', 'only_market', 'battery_first', 'ppo', 'recurrent_ppo']        #, 'recurrent_ppo']\n",
    "# colors = {e: col for e, col in zip(es, plotly.colors.sample_colorscale('rainbow', len(es)))}\n",
    "colors = plotly.colors.sample_colorscale('rainbow', env.num_battery_agents)\n",
    "line_styles = {'exp1': 'dot',\n",
    "               'only_market': 'dash',\n",
    "               'battery_first': 'dashdot',\n",
    "               'ppo': 'solid',\n",
    "               'recurrent_ppo': 'longdash'}\n",
    "\n",
    "def plot_data_plotly(demands, generations, sell_prices, buy_prices, log, exp, full_exp, agents, time_step, reward_type='weig_reward', cumulative=True):\n",
    "\n",
    "    n_points = max(demands.shape[0], generations.shape[0], sell_prices.shape[0], buy_prices.shape[0])\n",
    "    # print(n_points)\n",
    "    # print(demands.shape)\n",
    "\n",
    "    time = pd.date_range('2015-01-01', periods=n_points, freq=str(int(time_step))+'s')\n",
    "    fig = FigureWidgetResampler(make_subplots(rows=13, cols=1, shared_xaxes=True, vertical_spacing = 0.02, subplot_titles=['Power demand and generation', 'Market prices', 'SoC', 'Trad plus deg plus glob reward', 'Trading reward', 'Degradation reward', 'Clipping reward', 'Global reward', 'Actions', 'REC actions', 'REC reward','REC balances', 'Network exchange']), default_n_shown_samples=5000)\n",
    "    # fig = make_subplots(rows=11, cols=1, shared_xaxes=True, vertical_spacing = 0.05, subplot_titles=['Power demand and generation', 'Market prices', 'SoC', 'Total reward', 'Trading reward', 'Degradation reward', 'Clipping reward', 'Global reward', 'Actions', 'REC reward', 'REC balances'])\n",
    "\n",
    "    # print(time.shape)\n",
    "    # print(demands[: 0].shape)\n",
    "\n",
    "    for i in range(demands.shape[1]):\n",
    "        fig.add_trace(go.Scatter(x=time, y=demands[:, i], mode='lines', legend='legend1', name=f'demand {agents[exp[0]][i]}', line=dict(color=colors[i], dash='solid')), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=generations[:, i], mode='lines', legend='legend1', name=f'generation  {agents[exp[0]][i]}', line=dict(color=colors[i], dash='dot')), row=1, col=1)\n",
    "\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=time, y=sell_prices[:, 0]*1000000, mode='lines', legend='legend2', name='Selling prices'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=time, y=buy_prices[:, 0]*1000000, mode='lines', legend='legend2', name='Buying prices'), row=2, col=1)\n",
    "\n",
    "    rewards = {}\n",
    "    for e in exp:\n",
    "        rewards[e] = {}\n",
    "\n",
    "    if cumulative:\n",
    "        for e in exp:\n",
    "            rewards[e]['r_tot'] = np.cumsum(log[e]['r_tot'], axis=0)\n",
    "            rewards[e]['r_trad'] = np.cumsum(log[e][reward_type]['r_trad'], axis=0)\n",
    "            rewards[e]['r_deg'] = np.cumsum(log[e][reward_type]['r_deg'], axis=0)\n",
    "            rewards[e]['r_clipping'] = np.cumsum(log[e][reward_type]['r_clipping'], axis=0)\n",
    "            rewards[e]['r_glob'] = np.cumsum(log[e]['weig_reward']['r_glob'], axis=0)\n",
    "            rewards[e]['r_rec'] = np.cumsum(log[e]['rec_reward'])\n",
    "    else:\n",
    "        for e in exp:\n",
    "            rewards[e]['r_tot'] = log[e]['r_tot']\n",
    "            rewards[e]['r_trad'] = log[e][reward_type]['r_trad']\n",
    "            rewards[e]['r_deg'] = log[e][reward_type]['r_deg']\n",
    "            rewards[e]['r_clipping'] = log[e][reward_type]['r_clipping']\n",
    "            rewards[e]['r_glob'] = log[e]['weig_reward']['r_glob']\n",
    "            rewards[e]['r_rec'] = log[e]['rec_reward']\n",
    "\n",
    "    for e in full_exp:\n",
    "        for i in range(demands.shape[1]):\n",
    "            fig.add_trace(go.Scatter(x=time, y=log[e]['soc'][:, i], line=dict(color=colors[i], dash=line_styles[e]), mode='lines', legend='legend3', name=f'{e} {agents[e][i]}'), row=3, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_trad'][:, i]+rewards[e]['r_deg'][:, i]+rewards[e]['r_glob'][:, i], line=dict(color=colors[i], dash=line_styles[e]), mode='lines', legend='legend4', name=f'{e} {agents[e][i]}'), row=4, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_trad'][:, i], line=dict(color=colors[i], dash=line_styles[e]), mode='lines', legend='legend5', name=f'{e} {agents[e][i]}'), row=5, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_deg'][:, i], line=dict(color=colors[i], dash=line_styles[e]), mode='lines', legend='legend6', name=f'{e} {agents[e][i]}'), row=6, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_clipping'][:, i], line=dict(color=colors[i], dash=line_styles[e]), mode='lines', legend='legend7', name=f'{e} {agents[e][i]}'), row=7, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_glob'][:, i], line=dict(color=colors[i], dash=line_styles[e]), mode='lines', legend='legend8', name=f'{e} {agents[e][i]}'), row=8, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=log[e]['actions_batteries'][:, i], line=dict(color=colors[i], dash=line_styles[e]), mode='lines', legend='legend9', name=f'{e} {agents[e][i]}'), row=9, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time, y=log[e]['generations'][:, i]-log[e]['demands'][:, i]-log[e]['energy_to_batteries'][:, i], line=dict(color=colors[i], dash=line_styles[e]), mode='lines', legend='legend13', name=f'{e} {agents[e][i]}'), row=13, col=1)\n",
    "\n",
    "    for e in [e for e in exp if e not in full_exp]:\n",
    "        fig.add_trace(go.Scatter(x=time, y=log[e]['soc'].mean(axis=1), line=dict(color='grey', dash=line_styles[e]), mode='lines', legend='legend3', name=e), row=3, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_trad'].mean(axis=1) + rewards[e]['r_deg'].mean(axis=1) + rewards[e]['r_glob'].mean(axis=1), line=dict(color='grey', dash=line_styles[e]), mode='lines', legend='legend4', name=e), row=4, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_trad'].mean(axis=1), line=dict(color='grey', dash=line_styles[e]), mode='lines', legend='legend5', name=e), row=5, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_deg'].mean(axis=1), line=dict(color='grey', dash=line_styles[e]), mode='lines', legend='legend6', name=e), row=6, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_clipping'].mean(axis=1), line=dict(color='grey', dash=line_styles[e]), mode='lines', legend='legend7', name=e), row=7, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_glob'].mean(axis=1), line=dict(color='grey', dash=line_styles[e]), mode='lines', legend='legend8', name=e), row=8, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=log[e]['actions_batteries'].mean(axis=1), line=dict(color='grey', dash=line_styles[e]), mode='lines', legend='legend9', name=e), row=9, col=1)\n",
    "\n",
    "    print(log[e]['actions_rec'][0].shape, time.shape)\n",
    "\n",
    "    for e in exp:\n",
    "        for i in range(demands.shape[1]):\n",
    "            fig.add_trace(go.Scatter(x=time, y=log[e]['actions_rec'][:, i], line=dict(color=colors[i], dash=line_styles[e]), mode='lines', legend='legend10', name=e), row=10, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=rewards[e]['r_rec'], line=dict(color='grey', dash=line_styles[e]), mode='lines', legend='legend11', name=e), row=11, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=log[e]['balance_plus'], line=dict(color='green', dash=line_styles[e]), mode='lines', legend='legend12', name=e), row=12, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=log[e]['balance_minus'], line=dict(color='red', dash=line_styles[e]), mode='lines', legend='legend12', name=e), row=12, col=1)\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='',\n",
    "        xaxis=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis2=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis3=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis4=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis5=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis6=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis7=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis8=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis9=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis10=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis11=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis12=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "        xaxis13=dict(tickformat='%b %d %H:00', showticklabels=True),\n",
    "\n",
    "        yaxis=dict(fixedrange=True, title='Wh', minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis2=dict(fixedrange=True, title='/MWh', minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis3=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis4=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis5=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis6=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis7=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis8=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis9=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis10=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis11=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis12=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "        yaxis13=dict(fixedrange=True, minor=dict(ticklen=6, tickcolor=\"black\", showgrid=True)),\n",
    "\n",
    "        height=3000,\n",
    "        width=1200,\n",
    "        legend_tracegroupgap=20\n",
    "    )\n",
    "\n",
    "    # fig.update_layout(\n",
    "    # legends=[\n",
    "    #     dict(x=1.05, y=0.95, tracegroup=\"group1\"),  # Legend for first subplot\n",
    "    #     dict(x=1.05, y=0.60, tracegroup=\"group2\"),  # Legend for second subplot\n",
    "    # ]\n",
    "    # )\n",
    "\n",
    "    fig.update_layout(\n",
    "        legend1=dict(\n",
    "            xref=\"container\",\n",
    "            yref=\"container\",\n",
    "            y=0.6),\n",
    "        legend2=dict(\n",
    "            xref=\"container\",\n",
    "            yref=\"container\",\n",
    "            y=0.1)\n",
    "    )\n",
    "\n",
    "    fig.write_html(directory + '/plots.html')\n",
    "    print(directory + '/plots.html')\n",
    "\n",
    "\n",
    "    display(fig)"
   ],
   "id": "7754ab14398c60b6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
